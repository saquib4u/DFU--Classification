{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asP3yxpdpQV"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import random\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "import warnings\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LwfnDV3eguR"
      },
      "source": [
        "def load_images_from_folder(folder):\n",
        "\timages = []\n",
        "\tdirs = os.listdir(folder)\n",
        "\n",
        "\tfor filename in dirs:\n",
        "\t\tif os.path.isfile(folder+filename):\n",
        "\t\t\tim = Image.open(folder+filename)\n",
        "\t\t\timResize = im.resize((224,224), Image.ANTIALIAS)\n",
        "\t\t\timResize = np.array(imResize)\n",
        "\t\t\tif imResize is not None:\n",
        "\t\t\t\timages.append(imResize)\n",
        "\treturn images\n",
        "\n",
        "\n",
        "def prepareData(parentPath):\n",
        "\n",
        "\t# Make a list of all the 0 label and 1 label images for train, val, and test sets\n",
        "\n",
        "\tall0_path = list()\n",
        "\n",
        "\n",
        "\tall1_path = list()\n",
        "\n",
        "\n",
        "\tall0_path.append(parentPath+'/Abnormal(Ulcer)/')\n",
        "\tall1_path.append(parentPath+'/Normal(Healthy skin)/')\n",
        "\n",
        "\n",
        "\t# Read images into respective lists\n",
        "\n",
        "\n",
        "\tallX = list()\n",
        "\tallY = list()\n",
        "\txTrain = list()\n",
        "\tyTrain = list()\n",
        "\txVal = list()\n",
        "\tyVal = list()\n",
        "\txTest = list()\n",
        "\tyTest = list()\n",
        "\n",
        "\t# Prepare all data for 0 class\n",
        "\tprint('\\n\\n Class Abnormal(Ulcer), reading started..\\n\\n')\n",
        "\n",
        "\n",
        "\ttempImgs = list()\n",
        "\ttempImgs = load_images_from_folder(all0_path[0])\n",
        "\tfor i in range(len(tempImgs)):\n",
        "\t\tallX.append(tempImgs[i])\n",
        "\t\tallY.append(0)\n",
        "\n",
        "\t# Prepare all data for 1 class\n",
        "\tprint('\\n\\n Class Normal(Healthy skin), reading started..\\n\\n')\n",
        "\ttempImgs = list()\n",
        "\ttempImgs = load_images_from_folder(all1_path[0])\n",
        "\tfor i in range(len(tempImgs)):\n",
        "\t\tallX.append(tempImgs[i])\n",
        "\t\tallY.append(1)\n",
        "\n",
        "\txTrain,xTest,yTrain,yTest = train_test_split(allX,allY, test_size=0.20, random_state=10, shuffle = True)\n",
        "\n",
        "\txpTrain,xVal,ypTrain,yVal = train_test_split(xTrain,yTrain, test_size=0.10, random_state=10, shuffle = True)\n",
        "\n",
        "\treturn xpTrain, ypTrain, xVal, yVal, xTest, yTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mobile Net"
      ],
      "metadata": {
        "id": "XXrnEckwRkrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet import MobileNet\n",
        "def MobileNet_transfer_actual(input_shape):\n",
        "  res = MobileNet(weights=None, include_top=False, input_shape=input_shape)\n",
        "  for layer in res.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(res)\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(units=1024, activation='relu'))\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "drQtAlKpRtOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VGG16"
      ],
      "metadata": {
        "id": "HrJVbp2tR295"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "def VGG16_transfer_actual(input_shape):\n",
        "  res = VGG16(weights=None, include_top=False, input_shape=input_shape)\n",
        "  for layer in res.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(res)\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(units=4096, activation='relu'))\n",
        "  model.add(Dense(units=4096, activation='relu'))\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "89e0_DONSAzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWzwMmrHKEry"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auroc(y_true, y_pred):\n",
        "  return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing dataset from google drive"
      ],
      "metadata": {
        "id": "98NIG_WMFnej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "parentPath='/content/drive/MyDrive/DFU/Patches'\n",
        "xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(parentPath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lv4GgX7sj3h",
        "outputId": "a92fda7b-4490-4954-9163-217dd8a4dfb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "\n",
            " Class Abnormal(Ulcer), reading started..\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Class Normal(Healthy skin), reading started..\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0mk9-MC8VRb"
      },
      "source": [
        "xTrain = np.array(xTrain)\n",
        "yTrain = np.array(yTrain)\n",
        "xVal = np.array(xVal)\n",
        "yVal = np.array(yVal)\n",
        "xTest = np.array(xTest)\n",
        "yTest = np.array(yTest)\n",
        "\n",
        "# Prepare the data\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "  input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "  input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "xTrain = xTrain / 255\n",
        "xVal = xVal / 255\n",
        "xTest = xTest / 255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking shape of Training, Validation and Test data"
      ],
      "metadata": {
        "id": "m_-az6ciE0NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(xTrain.shape)\n",
        "print(xVal.shape)\n",
        "print(xTest.shape)"
      ],
      "metadata": {
        "id": "hoyuCOyw2cCj",
        "outputId": "d64eb35a-ab25-4f47-fcbb-df9ff4bfabc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(759, 224, 224, 3)\n",
            "(85, 224, 224, 3)\n",
            "(211, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xwWqHyPhQ_F"
      },
      "source": [
        "testPreds2 , testPreds3 = 0 , 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Model"
      ],
      "metadata": {
        "id": "EPPMSMQJEvQl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL8BAkLUZJWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c0d739-9dcc-4807-ebf5-3c04547214ab"
      },
      "source": [
        "model1 = MobileNet_transfer_actual(input_shape)\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200, restore_best_weights=True)\n",
        "model1.fit(xTrain, yTrain, epochs=1000, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "testPreds2 = model1.predict(xTest)\n",
        "print(\"MobileNet done.\")\n",
        "\n",
        "model1 = VGG16_transfer_actual(input_shape)\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200, restore_best_weights=True)\n",
        "model1.fit(xTrain, yTrain, epochs=1000, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "testPreds3 = model1.predict(xTest)\n",
        "print(\"VGG16 done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              51381248  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,611,137\n",
            "Trainable params: 54,589,249\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "16/16 [==============================] - 17s 334ms/step - loss: 0.4684 - accuracy: 0.7760 - val_loss: 0.7006 - val_accuracy: 0.5176\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.4352 - accuracy: 0.8472 - val_loss: 0.7347 - val_accuracy: 0.5176\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.2677 - accuracy: 0.8946 - val_loss: 0.8408 - val_accuracy: 0.5176\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.1847 - accuracy: 0.9289 - val_loss: 0.9522 - val_accuracy: 0.5176\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.1383 - accuracy: 0.9460 - val_loss: 1.0451 - val_accuracy: 0.5176\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.1131 - accuracy: 0.9552 - val_loss: 1.2166 - val_accuracy: 0.5176\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.1275 - accuracy: 0.9552 - val_loss: 1.5011 - val_accuracy: 0.5176\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.1199 - accuracy: 0.9513 - val_loss: 1.3756 - val_accuracy: 0.5176\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.1292 - accuracy: 0.9539 - val_loss: 1.8312 - val_accuracy: 0.5176\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0961 - accuracy: 0.9684 - val_loss: 2.1838 - val_accuracy: 0.5176\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0733 - accuracy: 0.9710 - val_loss: 2.2427 - val_accuracy: 0.5176\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0767 - accuracy: 0.9750 - val_loss: 2.4896 - val_accuracy: 0.5176\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0961 - accuracy: 0.9657 - val_loss: 2.7053 - val_accuracy: 0.5176\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0741 - accuracy: 0.9671 - val_loss: 2.7803 - val_accuracy: 0.5176\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.1202 - accuracy: 0.9499 - val_loss: 2.7181 - val_accuracy: 0.5176\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 3s 187ms/step - loss: 0.1098 - accuracy: 0.9578 - val_loss: 2.9269 - val_accuracy: 0.5176\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0750 - accuracy: 0.9684 - val_loss: 3.1368 - val_accuracy: 0.5176\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0828 - accuracy: 0.9618 - val_loss: 3.4768 - val_accuracy: 0.5176\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 3.3456 - val_accuracy: 0.5176\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0432 - accuracy: 0.9855 - val_loss: 3.8493 - val_accuracy: 0.5176\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0562 - accuracy: 0.9789 - val_loss: 3.5982 - val_accuracy: 0.5176\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0647 - accuracy: 0.9710 - val_loss: 4.0320 - val_accuracy: 0.5176\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0588 - accuracy: 0.9802 - val_loss: 4.3217 - val_accuracy: 0.5176\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0769 - accuracy: 0.9736 - val_loss: 4.0896 - val_accuracy: 0.5176\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0769 - accuracy: 0.9684 - val_loss: 4.3836 - val_accuracy: 0.5176\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0509 - accuracy: 0.9842 - val_loss: 4.6662 - val_accuracy: 0.5176\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0608 - accuracy: 0.9789 - val_loss: 4.6738 - val_accuracy: 0.5176\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.1132 - accuracy: 0.9539 - val_loss: 4.4844 - val_accuracy: 0.5176\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0773 - accuracy: 0.9710 - val_loss: 4.5922 - val_accuracy: 0.5176\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0635 - accuracy: 0.9763 - val_loss: 4.7639 - val_accuracy: 0.5176\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 5.3482 - val_accuracy: 0.5176\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0488 - accuracy: 0.9829 - val_loss: 5.4683 - val_accuracy: 0.5176\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0811 - accuracy: 0.9671 - val_loss: 5.0551 - val_accuracy: 0.5176\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0468 - accuracy: 0.9842 - val_loss: 5.7101 - val_accuracy: 0.5176\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0540 - accuracy: 0.9829 - val_loss: 6.0484 - val_accuracy: 0.5176\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.1766 - accuracy: 0.9368 - val_loss: 5.5293 - val_accuracy: 0.5176\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0818 - accuracy: 0.9697 - val_loss: 5.4493 - val_accuracy: 0.5176\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0545 - accuracy: 0.9802 - val_loss: 5.7074 - val_accuracy: 0.5176\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.0573 - accuracy: 0.9776 - val_loss: 5.5255 - val_accuracy: 0.5176\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0519 - accuracy: 0.9776 - val_loss: 5.5622 - val_accuracy: 0.5176\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0448 - accuracy: 0.9868 - val_loss: 5.1787 - val_accuracy: 0.5176\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 5.2334 - val_accuracy: 0.5176\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.0362 - accuracy: 0.9855 - val_loss: 5.2861 - val_accuracy: 0.5176\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.0639 - accuracy: 0.9789 - val_loss: 4.0065 - val_accuracy: 0.5294\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.0554 - accuracy: 0.9842 - val_loss: 2.3979 - val_accuracy: 0.6706\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0685 - accuracy: 0.9789 - val_loss: 1.6672 - val_accuracy: 0.6118\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.0828 - accuracy: 0.9736 - val_loss: 0.5926 - val_accuracy: 0.8235\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.0685 - accuracy: 0.9789 - val_loss: 0.1990 - val_accuracy: 0.9412\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.4040 - val_accuracy: 0.9294\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.3175 - val_accuracy: 0.9294\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0339 - accuracy: 0.9881 - val_loss: 0.2636 - val_accuracy: 0.9059\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0259 - accuracy: 0.9881 - val_loss: 0.2272 - val_accuracy: 0.9412\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.2767 - val_accuracy: 0.9412\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 0.2605 - val_accuracy: 0.9647\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0267 - accuracy: 0.9868 - val_loss: 0.3690 - val_accuracy: 0.9059\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.2281 - val_accuracy: 0.9765\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 0.3005 - val_accuracy: 0.9529\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.2602 - val_accuracy: 0.9647\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0538 - accuracy: 0.9802 - val_loss: 0.2509 - val_accuracy: 0.9647\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0296 - accuracy: 0.9895 - val_loss: 0.2381 - val_accuracy: 0.9765\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.2612 - val_accuracy: 0.9647\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.3070 - val_accuracy: 0.9765\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0724 - accuracy: 0.9789 - val_loss: 0.3695 - val_accuracy: 0.9529\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.1214 - accuracy: 0.9499 - val_loss: 0.5674 - val_accuracy: 0.8941\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0838 - accuracy: 0.9697 - val_loss: 0.2093 - val_accuracy: 0.9529\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0442 - accuracy: 0.9829 - val_loss: 0.4618 - val_accuracy: 0.8941\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.4996 - val_accuracy: 0.9059\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0448 - accuracy: 0.9829 - val_loss: 0.5868 - val_accuracy: 0.9059\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0399 - accuracy: 0.9855 - val_loss: 1.3738 - val_accuracy: 0.8000\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0586 - accuracy: 0.9750 - val_loss: 0.2632 - val_accuracy: 0.9412\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0510 - accuracy: 0.9789 - val_loss: 0.2835 - val_accuracy: 0.9176\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0377 - accuracy: 0.9829 - val_loss: 0.3976 - val_accuracy: 0.9059\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.0624 - accuracy: 0.9710 - val_loss: 0.3392 - val_accuracy: 0.9176\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 0.3252 - val_accuracy: 0.9529\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.2305 - val_accuracy: 0.9529\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0179 - accuracy: 0.9921 - val_loss: 0.2139 - val_accuracy: 0.9765\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.2203 - val_accuracy: 0.9529\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0209 - accuracy: 0.9908 - val_loss: 0.1836 - val_accuracy: 0.9647\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.1944 - val_accuracy: 0.9765\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0329 - accuracy: 0.9881 - val_loss: 0.1419 - val_accuracy: 0.9765\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0456 - accuracy: 0.9829 - val_loss: 0.1608 - val_accuracy: 0.9765\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.1870 - val_accuracy: 0.9765\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.1601 - val_accuracy: 0.9765\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.1416 - val_accuracy: 0.9765\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0111 - accuracy: 0.9947 - val_loss: 0.1602 - val_accuracy: 0.9765\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.1798 - val_accuracy: 0.9765\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.2064 - val_accuracy: 0.9765\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 0.2871 - val_accuracy: 0.9529\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 0.2945 - val_accuracy: 0.9294\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.3757 - val_accuracy: 0.9176\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0250 - accuracy: 0.9895 - val_loss: 0.6872 - val_accuracy: 0.8471\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.6156 - val_accuracy: 0.8824\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.3551 - val_accuracy: 0.9647\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0242 - accuracy: 0.9868 - val_loss: 0.3472 - val_accuracy: 0.9294\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.2139 - val_accuracy: 0.9765\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.2581 - val_accuracy: 0.9765\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.2468 - val_accuracy: 0.9765\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.2521 - val_accuracy: 0.9765\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.2057 - val_accuracy: 0.9765\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.2896 - val_accuracy: 0.9647\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.2442 - val_accuracy: 0.9765\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0148 - accuracy: 0.9934 - val_loss: 0.3048 - val_accuracy: 0.9765\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.6537 - val_accuracy: 0.9176\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.5647 - val_accuracy: 0.9529\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0115 - accuracy: 0.9947 - val_loss: 0.4295 - val_accuracy: 0.9647\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.4319 - val_accuracy: 0.9412\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.3807 - val_accuracy: 0.9765\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0143 - accuracy: 0.9934 - val_loss: 0.5171 - val_accuracy: 0.9529\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.5896 - val_accuracy: 0.9412\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0290 - accuracy: 0.9868 - val_loss: 0.7087 - val_accuracy: 0.8941\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0226 - accuracy: 0.9895 - val_loss: 0.5912 - val_accuracy: 0.9176\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0307 - accuracy: 0.9881 - val_loss: 0.3496 - val_accuracy: 0.9412\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0218 - accuracy: 0.9908 - val_loss: 0.3402 - val_accuracy: 0.9412\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.2645 - val_accuracy: 0.9647\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9647\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0076 - accuracy: 0.9960 - val_loss: 0.2379 - val_accuracy: 0.9765\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.1999 - val_accuracy: 0.9765\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9765\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9765\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0175 - accuracy: 0.9934 - val_loss: 0.1901 - val_accuracy: 0.9765\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 0.5311 - val_accuracy: 0.8941\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 0.2327 - val_accuracy: 0.9647\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0342 - accuracy: 0.9842 - val_loss: 0.1375 - val_accuracy: 0.9765\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.1491 - val_accuracy: 0.9647\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0193 - accuracy: 0.9921 - val_loss: 0.1676 - val_accuracy: 0.9765\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0926 - accuracy: 0.9750 - val_loss: 0.3018 - val_accuracy: 0.9294\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0469 - accuracy: 0.9829 - val_loss: 0.0735 - val_accuracy: 0.9765\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.1842 - val_accuracy: 0.9529\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.1464 - accuracy: 0.9460 - val_loss: 0.1830 - val_accuracy: 0.9765\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 0.5797 - val_accuracy: 0.9294\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.3323 - val_accuracy: 0.9412\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.3566 - val_accuracy: 0.9765\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.3234 - val_accuracy: 0.9765\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.2304 - val_accuracy: 0.9765\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0827 - accuracy: 0.9776 - val_loss: 0.3018 - val_accuracy: 0.9412\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.2535 - val_accuracy: 0.9765\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0198 - accuracy: 0.9895 - val_loss: 0.1921 - val_accuracy: 0.9765\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0333 - accuracy: 0.9908 - val_loss: 0.2093 - val_accuracy: 0.9765\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.3261 - val_accuracy: 0.9765\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.3193 - val_accuracy: 0.9647\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.2483 - val_accuracy: 0.9765\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9765\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9765\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9765\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0076 - accuracy: 0.9947 - val_loss: 0.2364 - val_accuracy: 0.9765\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.3673 - val_accuracy: 0.9765\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9765\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9765\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.3226 - val_accuracy: 0.9765\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9765\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9765\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9765\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9765\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0233 - accuracy: 0.9947 - val_loss: 0.3137 - val_accuracy: 0.9765\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.3863 - val_accuracy: 0.9765\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.3223 - val_accuracy: 0.9765\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0329 - accuracy: 0.9881 - val_loss: 0.2967 - val_accuracy: 0.9765\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0179 - accuracy: 0.9895 - val_loss: 0.3425 - val_accuracy: 0.9765\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.3722 - val_accuracy: 0.9765\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.3731 - val_accuracy: 0.9765\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0190 - accuracy: 0.9960 - val_loss: 0.3526 - val_accuracy: 0.9765\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0314 - accuracy: 0.9868 - val_loss: 0.4924 - val_accuracy: 0.9059\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0244 - accuracy: 0.9934 - val_loss: 0.8636 - val_accuracy: 0.8941\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.4473 - val_accuracy: 0.9529\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.2997 - val_accuracy: 0.9765\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.3350 - val_accuracy: 0.9647\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.2635 - val_accuracy: 0.9647\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.2431 - val_accuracy: 0.9765\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.2512 - val_accuracy: 0.9765\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0088 - accuracy: 0.9960 - val_loss: 0.2639 - val_accuracy: 0.9765\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0144 - accuracy: 0.9934 - val_loss: 0.2655 - val_accuracy: 0.9765\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0250 - accuracy: 0.9895 - val_loss: 0.2539 - val_accuracy: 0.9765\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.2021 - val_accuracy: 0.9765\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.2003 - val_accuracy: 0.9765\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9647\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0263 - accuracy: 0.9934 - val_loss: 0.2801 - val_accuracy: 0.9647\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.2749 - val_accuracy: 0.9765\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.2676 - val_accuracy: 0.9765\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.2507 - val_accuracy: 0.9765\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9765\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9765\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.2525 - val_accuracy: 0.9765\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.2953 - val_accuracy: 0.9765\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 0.3357 - val_accuracy: 0.9412\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0371 - accuracy: 0.9868 - val_loss: 0.3397 - val_accuracy: 0.9294\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0597 - accuracy: 0.9868 - val_loss: 0.2593 - val_accuracy: 0.9765\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.1287 - accuracy: 0.9539 - val_loss: 0.1212 - val_accuracy: 0.9765\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.1368 - val_accuracy: 0.9765\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0245 - accuracy: 0.9947 - val_loss: 0.1333 - val_accuracy: 0.9765\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.2348 - val_accuracy: 0.9765\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.2162 - val_accuracy: 0.9765\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.1827 - val_accuracy: 0.9765\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.1664 - val_accuracy: 0.9765\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1521 - val_accuracy: 0.9765\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 3s 198ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.1140 - val_accuracy: 0.9765\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.1417 - val_accuracy: 0.9765\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0081 - accuracy: 0.9960 - val_loss: 0.1499 - val_accuracy: 0.9765\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9765\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9765\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9765\n",
            "Epoch 201/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.1389 - val_accuracy: 0.9765\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.1362 - val_accuracy: 0.9765\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0095 - accuracy: 0.9960 - val_loss: 0.2100 - val_accuracy: 0.9647\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 0.1045 - val_accuracy: 0.9765\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.1121 - val_accuracy: 0.9765\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1356 - val_accuracy: 0.9765\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.1504 - val_accuracy: 0.9765\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.1037 - val_accuracy: 0.9765\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.1023 - val_accuracy: 0.9765\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.1131 - val_accuracy: 0.9765\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1916 - val_accuracy: 0.9647\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0101 - accuracy: 0.9960 - val_loss: 0.1753 - val_accuracy: 0.9765\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9765\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1799 - val_accuracy: 0.9765\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0162 - accuracy: 0.9934 - val_loss: 0.1782 - val_accuracy: 0.9765\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.1733 - val_accuracy: 0.9765\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 0.1811 - val_accuracy: 0.9765\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.1767 - val_accuracy: 0.9765\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1925 - val_accuracy: 0.9765\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0182 - accuracy: 0.9934 - val_loss: 0.1902 - val_accuracy: 0.9647\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.2740 - val_accuracy: 0.9529\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.3254 - val_accuracy: 0.9412\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0131 - accuracy: 0.9934 - val_loss: 0.2342 - val_accuracy: 0.9647\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0112 - accuracy: 0.9947 - val_loss: 0.2261 - val_accuracy: 0.9647\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9765\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.2241 - val_accuracy: 0.9765\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.3514 - val_accuracy: 0.9294\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.2211 - val_accuracy: 0.9529\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9765\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.1435 - val_accuracy: 0.9765\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9765\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1348 - val_accuracy: 0.9765\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.1983 - val_accuracy: 0.9765\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0546 - accuracy: 0.9802 - val_loss: 0.3118 - val_accuracy: 0.9765\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 0.0147 - accuracy: 0.9908 - val_loss: 0.3490 - val_accuracy: 0.9412\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.2260 - val_accuracy: 0.9529\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.1863 - val_accuracy: 0.9765\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9765\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 3s 195ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9765\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0042 - accuracy: 0.9974 - val_loss: 0.1668 - val_accuracy: 0.9765\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 3s 192ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.1883 - val_accuracy: 0.9765\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.2852 - val_accuracy: 0.9765\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.2597 - val_accuracy: 0.9765\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0041 - accuracy: 0.9974 - val_loss: 0.2474 - val_accuracy: 0.9765\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.2236 - val_accuracy: 0.9765\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.2494 - val_accuracy: 0.9765\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 3s 194ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.2377 - val_accuracy: 0.9765\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0225 - accuracy: 0.9934 - val_loss: 0.2322 - val_accuracy: 0.9765\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 3s 188ms/step - loss: 0.0158 - accuracy: 0.9934 - val_loss: 0.1887 - val_accuracy: 0.9765\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0206 - accuracy: 0.9908 - val_loss: 0.1965 - val_accuracy: 0.9765\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.2152 - val_accuracy: 0.9529\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.1956 - val_accuracy: 0.9765\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.2083 - val_accuracy: 0.9765\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 3s 189ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.2760 - val_accuracy: 0.9765\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 3s 190ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.2695 - val_accuracy: 0.9765\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987Restoring model weights from the end of the best epoch: 56.\n",
            "16/16 [==============================] - 3s 220ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.2362 - val_accuracy: 0.9765\n",
            "Epoch 256: early stopping\n",
            "7/7 [==============================] - 1s 82ms/step\n",
            "MobileNet done.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,264,641\n",
            "Trainable params: 134,264,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "16/16 [==============================] - 32s 1s/step - loss: 0.6931 - accuracy: 0.5534 - val_loss: 0.6929 - val_accuracy: 0.5176\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.6928 - accuracy: 0.5033 - val_loss: 0.6927 - val_accuracy: 0.5176\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.6927 - accuracy: 0.5033 - val_loss: 0.6926 - val_accuracy: 0.5176\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.6926 - accuracy: 0.5033 - val_loss: 0.6925 - val_accuracy: 0.5176\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.6925 - accuracy: 0.5033 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.6924 - accuracy: 0.5072 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 13s 797ms/step - loss: 0.6923 - accuracy: 0.5112 - val_loss: 0.6923 - val_accuracy: 0.5294\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 13s 795ms/step - loss: 0.6923 - accuracy: 0.7971 - val_loss: 0.6923 - val_accuracy: 0.7529\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.6921 - accuracy: 0.8129 - val_loss: 0.6921 - val_accuracy: 0.6824\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.6920 - accuracy: 0.5955 - val_loss: 0.6920 - val_accuracy: 0.5412\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.6920 - accuracy: 0.5046 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.6919 - accuracy: 0.5257 - val_loss: 0.6917 - val_accuracy: 0.5176\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.6918 - accuracy: 0.5428 - val_loss: 0.6916 - val_accuracy: 0.5176\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.6917 - accuracy: 0.5033 - val_loss: 0.6915 - val_accuracy: 0.5176\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 12s 747ms/step - loss: 0.6915 - accuracy: 0.5033 - val_loss: 0.6913 - val_accuracy: 0.5176\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.6914 - accuracy: 0.5046 - val_loss: 0.6913 - val_accuracy: 0.5176\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.6912 - accuracy: 0.5863 - val_loss: 0.6911 - val_accuracy: 0.5176\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.6910 - accuracy: 0.6061 - val_loss: 0.6909 - val_accuracy: 0.6353\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 13s 796ms/step - loss: 0.6909 - accuracy: 0.6337 - val_loss: 0.6908 - val_accuracy: 0.8000\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 12s 761ms/step - loss: 0.6908 - accuracy: 0.7734 - val_loss: 0.6909 - val_accuracy: 0.5882\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.6907 - accuracy: 0.6957 - val_loss: 0.6907 - val_accuracy: 0.6000\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 12s 784ms/step - loss: 0.6909 - accuracy: 0.6087 - val_loss: 0.6908 - val_accuracy: 0.8118\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.6905 - accuracy: 0.6166 - val_loss: 0.6898 - val_accuracy: 0.5647\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.6902 - accuracy: 0.7167 - val_loss: 0.6902 - val_accuracy: 0.5176\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.6898 - accuracy: 0.5784 - val_loss: 0.6892 - val_accuracy: 0.7176\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.6892 - accuracy: 0.6192 - val_loss: 0.6887 - val_accuracy: 0.5882\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 12s 760ms/step - loss: 0.6888 - accuracy: 0.6548 - val_loss: 0.6883 - val_accuracy: 0.5882\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 12s 748ms/step - loss: 0.6887 - accuracy: 0.6535 - val_loss: 0.6879 - val_accuracy: 0.5529\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.6882 - accuracy: 0.6812 - val_loss: 0.6874 - val_accuracy: 0.5412\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.6883 - accuracy: 0.6403 - val_loss: 0.6868 - val_accuracy: 0.5647\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 13s 802ms/step - loss: 0.6882 - accuracy: 0.6153 - val_loss: 0.6870 - val_accuracy: 0.9412\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.6866 - accuracy: 0.6430 - val_loss: 0.6856 - val_accuracy: 0.8471\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 12s 760ms/step - loss: 0.6866 - accuracy: 0.6495 - val_loss: 0.6846 - val_accuracy: 0.6706\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.6856 - accuracy: 0.6469 - val_loss: 0.6836 - val_accuracy: 0.5882\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.6836 - accuracy: 0.6798 - val_loss: 0.6821 - val_accuracy: 0.8824\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.6823 - accuracy: 0.7549 - val_loss: 0.6806 - val_accuracy: 0.6941\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.6807 - accuracy: 0.7905 - val_loss: 0.6816 - val_accuracy: 0.7765\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.6819 - accuracy: 0.6772 - val_loss: 0.6807 - val_accuracy: 0.7059\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.6782 - accuracy: 0.7945 - val_loss: 0.6756 - val_accuracy: 0.8235\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 12s 762ms/step - loss: 0.6745 - accuracy: 0.8458 - val_loss: 0.6714 - val_accuracy: 0.8824\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 12s 763ms/step - loss: 0.6711 - accuracy: 0.8366 - val_loss: 0.6662 - val_accuracy: 0.9412\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 12s 761ms/step - loss: 0.6651 - accuracy: 0.8841 - val_loss: 0.6606 - val_accuracy: 0.8118\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.6591 - accuracy: 0.8458 - val_loss: 0.6541 - val_accuracy: 0.7882\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.6514 - accuracy: 0.8274 - val_loss: 0.6489 - val_accuracy: 0.8235\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.6505 - accuracy: 0.7286 - val_loss: 0.6285 - val_accuracy: 0.9294\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.6289 - accuracy: 0.8274 - val_loss: 0.6373 - val_accuracy: 0.6824\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 12s 747ms/step - loss: 0.6570 - accuracy: 0.6403 - val_loss: 0.6501 - val_accuracy: 0.9059\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.6244 - accuracy: 0.8195 - val_loss: 0.6561 - val_accuracy: 0.6235\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.6314 - accuracy: 0.6350 - val_loss: 0.6115 - val_accuracy: 0.7529\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.6066 - accuracy: 0.7681 - val_loss: 0.7289 - val_accuracy: 0.5176\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.6665 - accuracy: 0.5744 - val_loss: 0.6608 - val_accuracy: 0.5882\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.6107 - accuracy: 0.7036 - val_loss: 0.6090 - val_accuracy: 0.5882\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.5658 - accuracy: 0.7352 - val_loss: 0.6795 - val_accuracy: 0.5765\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.5590 - accuracy: 0.7299 - val_loss: 0.4998 - val_accuracy: 0.7529\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.4638 - accuracy: 0.8050 - val_loss: 0.3932 - val_accuracy: 0.9176\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.4123 - accuracy: 0.8340 - val_loss: 0.5316 - val_accuracy: 0.6706\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 13s 795ms/step - loss: 0.4100 - accuracy: 0.8195 - val_loss: 0.2364 - val_accuracy: 0.9529\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.5551 - accuracy: 0.7312 - val_loss: 0.5715 - val_accuracy: 0.6824\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.3773 - accuracy: 0.8893 - val_loss: 0.2808 - val_accuracy: 0.9529\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.2216 - accuracy: 0.9289 - val_loss: 0.4191 - val_accuracy: 0.8353\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.1854 - accuracy: 0.9433 - val_loss: 0.1493 - val_accuracy: 0.9412\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.1171 - accuracy: 0.9513 - val_loss: 0.1119 - val_accuracy: 0.9529\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 13s 801ms/step - loss: 0.1156 - accuracy: 0.9618 - val_loss: 0.0868 - val_accuracy: 0.9647\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.1064 - accuracy: 0.9578 - val_loss: 0.0874 - val_accuracy: 0.9647\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.1083 - accuracy: 0.9618 - val_loss: 0.1041 - val_accuracy: 0.9529\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 13s 799ms/step - loss: 0.0867 - accuracy: 0.9671 - val_loss: 0.0787 - val_accuracy: 0.9765\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0768 - accuracy: 0.9657 - val_loss: 0.0702 - val_accuracy: 0.9647\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0761 - accuracy: 0.9723 - val_loss: 0.0949 - val_accuracy: 0.9647\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.1522 - accuracy: 0.9368 - val_loss: 0.0825 - val_accuracy: 0.9765\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.1004 - accuracy: 0.9671 - val_loss: 0.1759 - val_accuracy: 0.9529\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0885 - accuracy: 0.9710 - val_loss: 0.1132 - val_accuracy: 0.9529\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0762 - accuracy: 0.9723 - val_loss: 0.0643 - val_accuracy: 0.9647\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0747 - accuracy: 0.9723 - val_loss: 0.1024 - val_accuracy: 0.9765\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 12s 747ms/step - loss: 0.0955 - accuracy: 0.9631 - val_loss: 0.0981 - val_accuracy: 0.9765\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.1776 - accuracy: 0.9315 - val_loss: 0.1555 - val_accuracy: 0.9529\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.1334 - accuracy: 0.9539 - val_loss: 0.1216 - val_accuracy: 0.9529\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0849 - accuracy: 0.9644 - val_loss: 0.1783 - val_accuracy: 0.9529\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0844 - accuracy: 0.9723 - val_loss: 0.0727 - val_accuracy: 0.9647\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0775 - accuracy: 0.9710 - val_loss: 0.4667 - val_accuracy: 0.8706\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 12s 760ms/step - loss: 0.2199 - accuracy: 0.9275 - val_loss: 0.0964 - val_accuracy: 0.9765\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 12s 761ms/step - loss: 0.0920 - accuracy: 0.9671 - val_loss: 0.1608 - val_accuracy: 0.9529\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0657 - accuracy: 0.9776 - val_loss: 0.0718 - val_accuracy: 0.9765\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0681 - accuracy: 0.9763 - val_loss: 0.0569 - val_accuracy: 0.9647\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0774 - accuracy: 0.9684 - val_loss: 0.0676 - val_accuracy: 0.9647\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0637 - accuracy: 0.9736 - val_loss: 0.0556 - val_accuracy: 0.9765\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.1169 - val_accuracy: 0.9529\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0493 - accuracy: 0.9802 - val_loss: 0.0965 - val_accuracy: 0.9529\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0875 - val_accuracy: 0.9529\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.1584 - val_accuracy: 0.9412\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0543 - accuracy: 0.9776 - val_loss: 0.1766 - val_accuracy: 0.9529\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 0.1230 - val_accuracy: 0.9765\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 12s 760ms/step - loss: 0.0845 - accuracy: 0.9671 - val_loss: 0.1256 - val_accuracy: 0.9529\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0497 - accuracy: 0.9802 - val_loss: 0.1062 - val_accuracy: 0.9529\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0579 - accuracy: 0.9829 - val_loss: 0.0381 - val_accuracy: 0.9765\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0578 - accuracy: 0.9763 - val_loss: 0.0584 - val_accuracy: 0.9647\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0441 - accuracy: 0.9802 - val_loss: 0.0895 - val_accuracy: 0.9765\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 0.0878 - val_accuracy: 0.9765\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0523 - accuracy: 0.9816 - val_loss: 0.0957 - val_accuracy: 0.9765\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.1063 - val_accuracy: 0.9765\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 12s 780ms/step - loss: 0.0939 - accuracy: 0.9697 - val_loss: 0.0943 - val_accuracy: 0.9882\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - 12s 760ms/step - loss: 0.2306 - accuracy: 0.9170 - val_loss: 0.0788 - val_accuracy: 0.9529\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.1560 - accuracy: 0.9394 - val_loss: 0.0794 - val_accuracy: 0.9529\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.1257 - accuracy: 0.9539 - val_loss: 0.1083 - val_accuracy: 0.9529\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0857 - accuracy: 0.9671 - val_loss: 0.0564 - val_accuracy: 0.9882\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0664 - accuracy: 0.9750 - val_loss: 0.0560 - val_accuracy: 0.9882\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0393 - val_accuracy: 0.9882\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0777 - accuracy: 0.9671 - val_loss: 0.0911 - val_accuracy: 0.9765\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 0.0523 - accuracy: 0.9789 - val_loss: 0.0692 - val_accuracy: 0.9765\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0444 - accuracy: 0.9802 - val_loss: 0.0421 - val_accuracy: 0.9882\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0536 - accuracy: 0.9816 - val_loss: 0.1195 - val_accuracy: 0.9765\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0439 - accuracy: 0.9802 - val_loss: 0.0803 - val_accuracy: 0.9765\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0430 - accuracy: 0.9789 - val_loss: 0.0790 - val_accuracy: 0.9765\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0356 - accuracy: 0.9816 - val_loss: 0.0314 - val_accuracy: 0.9882\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0400 - accuracy: 0.9842 - val_loss: 0.0427 - val_accuracy: 0.9882\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0500 - accuracy: 0.9789 - val_loss: 0.0673 - val_accuracy: 0.9765\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 12s 738ms/step - loss: 0.0537 - accuracy: 0.9763 - val_loss: 0.0615 - val_accuracy: 0.9765\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0460 - accuracy: 0.9802 - val_loss: 0.1402 - val_accuracy: 0.9765\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.1644 - val_accuracy: 0.9529\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0550 - accuracy: 0.9776 - val_loss: 0.0592 - val_accuracy: 0.9765\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0506 - accuracy: 0.9763 - val_loss: 0.0351 - val_accuracy: 0.9882\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0406 - accuracy: 0.9842 - val_loss: 0.0609 - val_accuracy: 0.9765\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 0.0468 - accuracy: 0.9816 - val_loss: 0.0327 - val_accuracy: 0.9882\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 0.0374 - val_accuracy: 0.9882\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0350 - accuracy: 0.9855 - val_loss: 0.0500 - val_accuracy: 0.9765\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.0402 - val_accuracy: 0.9765\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0381 - accuracy: 0.9829 - val_loss: 0.0459 - val_accuracy: 0.9765\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.0502 - val_accuracy: 0.9765\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0354 - accuracy: 0.9842 - val_loss: 0.0727 - val_accuracy: 0.9765\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.0733 - val_accuracy: 0.9765\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.1165 - val_accuracy: 0.9765\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0667 - accuracy: 0.9776 - val_loss: 0.0657 - val_accuracy: 0.9765\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0605 - accuracy: 0.9763 - val_loss: 0.0739 - val_accuracy: 0.9765\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0498 - accuracy: 0.9829 - val_loss: 0.0430 - val_accuracy: 0.9765\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.0376 - val_accuracy: 0.9882\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0297 - accuracy: 0.9881 - val_loss: 0.0391 - val_accuracy: 0.9882\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0298 - accuracy: 0.9868 - val_loss: 0.0275 - val_accuracy: 0.9882\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.0320 - val_accuracy: 0.9882\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.0625 - val_accuracy: 0.9765\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 0.0690 - val_accuracy: 0.9765\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.1091 - val_accuracy: 0.9765\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0490 - accuracy: 0.9816 - val_loss: 0.0670 - val_accuracy: 0.9765\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0287 - accuracy: 0.9881 - val_loss: 0.0772 - val_accuracy: 0.9765\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0251 - accuracy: 0.9881 - val_loss: 0.0591 - val_accuracy: 0.9765\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.1186 - val_accuracy: 0.9765\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0198 - accuracy: 0.9921 - val_loss: 0.1293 - val_accuracy: 0.9765\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0445 - accuracy: 0.9829 - val_loss: 0.1784 - val_accuracy: 0.9765\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0510 - accuracy: 0.9763 - val_loss: 0.0490 - val_accuracy: 0.9882\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 13s 799ms/step - loss: 0.0819 - accuracy: 0.9671 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0413 - accuracy: 0.9908 - val_loss: 0.0592 - val_accuracy: 0.9765\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 0.0254 - accuracy: 0.9908 - val_loss: 0.1003 - val_accuracy: 0.9765\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.0618 - val_accuracy: 0.9765\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0313 - val_accuracy: 0.9882\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0354 - accuracy: 0.9829 - val_loss: 0.0636 - val_accuracy: 0.9765\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0244 - accuracy: 0.9895 - val_loss: 0.0717 - val_accuracy: 0.9765\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0459 - val_accuracy: 0.9765\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.0446 - val_accuracy: 0.9882\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0236 - accuracy: 0.9908 - val_loss: 0.0535 - val_accuracy: 0.9765\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.0800 - val_accuracy: 0.9765\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0128 - accuracy: 0.9987 - val_loss: 0.0583 - val_accuracy: 0.9765\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 0.0878 - val_accuracy: 0.9765\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.0685 - val_accuracy: 0.9765\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0196 - accuracy: 0.9921 - val_loss: 0.0635 - val_accuracy: 0.9765\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0498 - accuracy: 0.9816 - val_loss: 0.1056 - val_accuracy: 0.9765\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.1010 - val_accuracy: 0.9765\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0373 - accuracy: 0.9816 - val_loss: 0.1046 - val_accuracy: 0.9765\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0266 - accuracy: 0.9895 - val_loss: 0.1078 - val_accuracy: 0.9765\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.1091 - val_accuracy: 0.9765\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0109 - accuracy: 0.9987 - val_loss: 0.0603 - val_accuracy: 0.9765\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.1735 - val_accuracy: 0.9765\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.1493 - val_accuracy: 0.9765\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0194 - accuracy: 0.9895 - val_loss: 0.1111 - val_accuracy: 0.9765\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0680 - val_accuracy: 0.9882\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.0992 - val_accuracy: 0.9765\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.1091 - val_accuracy: 0.9765\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.0640 - val_accuracy: 0.9765\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0516 - val_accuracy: 0.9882\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0983 - val_accuracy: 0.9765\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0815 - val_accuracy: 0.9765\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.0888 - val_accuracy: 0.9765\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0871 - val_accuracy: 0.9765\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0766 - val_accuracy: 0.9765\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1132 - val_accuracy: 0.9765\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.1243 - val_accuracy: 0.9765\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9882\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0351 - val_accuracy: 0.9882\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0115 - accuracy: 0.9947 - val_loss: 0.0704 - val_accuracy: 0.9882\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0166 - accuracy: 0.9908 - val_loss: 0.0616 - val_accuracy: 0.9882\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0861 - val_accuracy: 0.9765\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.1303 - val_accuracy: 0.9765\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.1481 - val_accuracy: 0.9765\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1411 - val_accuracy: 0.9765\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9765\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0746 - val_accuracy: 0.9765\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0523 - val_accuracy: 0.9882\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.1423 - val_accuracy: 0.9765\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9765\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.1411 - val_accuracy: 0.9765\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0668 - accuracy: 0.9763 - val_loss: 0.0575 - val_accuracy: 0.9765\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0939 - val_accuracy: 0.9765\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.1164 - val_accuracy: 0.9765\n",
            "Epoch 201/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0847 - val_accuracy: 0.9765\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.1162 - val_accuracy: 0.9765\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0922 - val_accuracy: 0.9765\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1230 - val_accuracy: 0.9765\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9765\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0886 - val_accuracy: 0.9765\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9765\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9765\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9765\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9765\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.1169 - val_accuracy: 0.9765\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0941 - val_accuracy: 0.9765\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.2334 - val_accuracy: 0.9765\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0385 - accuracy: 0.9842 - val_loss: 0.0429 - val_accuracy: 0.9765\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.0833 - val_accuracy: 0.9765\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.0573 - val_accuracy: 0.9882\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.1020 - val_accuracy: 0.9765\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9765\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9765\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9765\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9765\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9765\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9765\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9765\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9765\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9765\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9765\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9765\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9765\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9765\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9765\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9765\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9765\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 12s 762ms/step - loss: 9.4105e-04 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9765\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 9.2129e-04 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9765\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 8.9637e-04 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9765\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 12s 738ms/step - loss: 7.1564e-04 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9765\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 7.3755e-04 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9765\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 7.0062e-04 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9765\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 7.3528e-04 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9765\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 6.5987e-04 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9765\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 6.2114e-04 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9765\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 5.8572e-04 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9765\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 5.5023e-04 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9765\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 12s 738ms/step - loss: 5.4594e-04 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9765\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 5.3440e-04 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9765\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 5.2179e-04 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9765\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 5.3238e-04 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9765\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 12s 756ms/step - loss: 5.0397e-04 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9765\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 5.0928e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9765\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 5.3021e-04 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9765\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 4.4538e-04 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9765\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 4.2717e-04 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9765\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 12s 737ms/step - loss: 4.2655e-04 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9765\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 4.2311e-04 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9765\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 4.6379e-04 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9765\n",
            "Epoch 257/1000\n",
            "16/16 [==============================] - 12s 736ms/step - loss: 4.0094e-04 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9765\n",
            "Epoch 258/1000\n",
            "16/16 [==============================] - 12s 750ms/step - loss: 4.1252e-04 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9765\n",
            "Epoch 259/1000\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 3.7868e-04 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9765\n",
            "Epoch 260/1000\n",
            "16/16 [==============================] - 12s 754ms/step - loss: 4.1615e-04 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9765\n",
            "Epoch 261/1000\n",
            "16/16 [==============================] - 12s 750ms/step - loss: 3.8855e-04 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9765\n",
            "Epoch 262/1000\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 3.8334e-04 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9765\n",
            "Epoch 263/1000\n",
            "16/16 [==============================] - 12s 738ms/step - loss: 3.8028e-04 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9765\n",
            "Epoch 264/1000\n",
            "16/16 [==============================] - 12s 752ms/step - loss: 3.7260e-04 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9765\n",
            "Epoch 265/1000\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 6.3802e-04 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9765\n",
            "Epoch 266/1000\n",
            "16/16 [==============================] - 12s 750ms/step - loss: 6.3241e-04 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9765\n",
            "Epoch 267/1000\n",
            "16/16 [==============================] - 12s 738ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9765\n",
            "Epoch 268/1000\n",
            "16/16 [==============================] - 12s 751ms/step - loss: 3.7752e-04 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9765\n",
            "Epoch 269/1000\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 3.2572e-04 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9765\n",
            "Epoch 270/1000\n",
            "16/16 [==============================] - 12s 735ms/step - loss: 3.0439e-04 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9765\n",
            "Epoch 271/1000\n",
            "16/16 [==============================] - 12s 734ms/step - loss: 3.3985e-04 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9765\n",
            "Epoch 272/1000\n",
            "16/16 [==============================] - 12s 732ms/step - loss: 3.5791e-04 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9765\n",
            "Epoch 273/1000\n",
            "16/16 [==============================] - 12s 750ms/step - loss: 3.6182e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9765\n",
            "Epoch 274/1000\n",
            "16/16 [==============================] - 12s 735ms/step - loss: 2.9004e-04 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9765\n",
            "Epoch 275/1000\n",
            "16/16 [==============================] - 12s 731ms/step - loss: 2.7231e-04 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9765\n",
            "Epoch 276/1000\n",
            "16/16 [==============================] - 12s 733ms/step - loss: 2.7192e-04 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9765\n",
            "Epoch 277/1000\n",
            "16/16 [==============================] - 12s 749ms/step - loss: 2.7450e-04 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9765\n",
            "Epoch 278/1000\n",
            "16/16 [==============================] - 12s 735ms/step - loss: 2.8116e-04 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9765\n",
            "Epoch 279/1000\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 2.4992e-04 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9765\n",
            "Epoch 280/1000\n",
            "16/16 [==============================] - 12s 749ms/step - loss: 2.4504e-04 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9765\n",
            "Epoch 281/1000\n",
            "16/16 [==============================] - 12s 731ms/step - loss: 2.3905e-04 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9765\n",
            "Epoch 282/1000\n",
            "16/16 [==============================] - 12s 734ms/step - loss: 2.4341e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9765\n",
            "Epoch 283/1000\n",
            "16/16 [==============================] - 12s 736ms/step - loss: 2.2977e-04 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9765\n",
            "Epoch 284/1000\n",
            "16/16 [==============================] - 12s 736ms/step - loss: 2.2437e-04 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9765\n",
            "Epoch 285/1000\n",
            "16/16 [==============================] - 12s 731ms/step - loss: 2.2404e-04 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9765\n",
            "Epoch 286/1000\n",
            "16/16 [==============================] - 12s 732ms/step - loss: 2.5082e-04 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9765\n",
            "Epoch 287/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 2.2249e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9765\n",
            "Epoch 288/1000\n",
            "16/16 [==============================] - 12s 747ms/step - loss: 2.2264e-04 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9765\n",
            "Epoch 289/1000\n",
            "16/16 [==============================] - 12s 748ms/step - loss: 2.0151e-04 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9765\n",
            "Epoch 290/1000\n",
            "16/16 [==============================] - 12s 733ms/step - loss: 2.4380e-04 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9765\n",
            "Epoch 291/1000\n",
            "16/16 [==============================] - 12s 735ms/step - loss: 2.3752e-04 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9765\n",
            "Epoch 292/1000\n",
            "16/16 [==============================] - 12s 747ms/step - loss: 3.1195e-04 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9765\n",
            "Epoch 293/1000\n",
            "16/16 [==============================] - 12s 735ms/step - loss: 2.0390e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9765\n",
            "Epoch 294/1000\n",
            "16/16 [==============================] - 12s 730ms/step - loss: 2.0937e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9765\n",
            "Epoch 295/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 1.8997e-04 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9765\n",
            "Epoch 296/1000\n",
            "16/16 [==============================] - 12s 732ms/step - loss: 1.9347e-04 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9765\n",
            "Epoch 297/1000\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 1.8245e-04 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9765\n",
            "Epoch 298/1000\n",
            "16/16 [==============================] - 12s 748ms/step - loss: 1.8383e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9765\n",
            "Epoch 299/1000\n",
            "16/16 [==============================] - 12s 733ms/step - loss: 1.7535e-04 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9765\n",
            "Epoch 300/1000\n",
            "16/16 [==============================] - 12s 730ms/step - loss: 1.7432e-04 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9765\n",
            "Epoch 301/1000\n",
            "16/16 [==============================] - 12s 734ms/step - loss: 1.8109e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9765\n",
            "Epoch 302/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 1.9266e-04 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9765\n",
            "Epoch 303/1000\n",
            "16/16 [==============================] - 12s 732ms/step - loss: 1.6452e-04 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9765\n",
            "Epoch 304/1000\n",
            "16/16 [==============================] - 12s 727ms/step - loss: 1.7226e-04 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9765\n",
            "Epoch 305/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 1.6514e-04 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9765\n",
            "Epoch 306/1000\n",
            "16/16 [==============================] - 12s 745ms/step - loss: 1.6019e-04 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9765\n",
            "Epoch 307/1000\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 1.5676e-04 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9765\n",
            "Epoch 308/1000\n",
            "16/16 [==============================] - 12s 726ms/step - loss: 1.6201e-04 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9765\n",
            "Epoch 309/1000\n",
            "16/16 [==============================] - 12s 727ms/step - loss: 1.8192e-04 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9765\n",
            "Epoch 310/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 1.6234e-04 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9765\n",
            "Epoch 311/1000\n",
            "16/16 [==============================] - 12s 732ms/step - loss: 1.5109e-04 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9765\n",
            "Epoch 312/1000\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 1.5046e-04 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9765\n",
            "Epoch 313/1000\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 1.4229e-04 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9765\n",
            "Epoch 314/1000\n",
            "16/16 [==============================] - 12s 736ms/step - loss: 1.4800e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9765\n",
            "Epoch 315/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 1.4150e-04 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9765\n",
            "Epoch 316/1000\n",
            "16/16 [==============================] - 12s 733ms/step - loss: 1.4559e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9765\n",
            "Epoch 317/1000\n",
            "16/16 [==============================] - 12s 726ms/step - loss: 1.4217e-04 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9765\n",
            "Epoch 318/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 1.3842e-04 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9765\n",
            "Epoch 319/1000\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 1.4403e-04 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9765\n",
            "Epoch 320/1000\n",
            "16/16 [==============================] - 12s 727ms/step - loss: 1.4053e-04 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9765\n",
            "Epoch 321/1000\n",
            "16/16 [==============================] - 12s 726ms/step - loss: 1.3993e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9765\n",
            "Epoch 322/1000\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 1.3988e-04 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9765\n",
            "Epoch 323/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 1.3910e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9765\n",
            "Epoch 324/1000\n",
            "16/16 [==============================] - 12s 726ms/step - loss: 1.4953e-04 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9765\n",
            "Epoch 325/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 1.2734e-04 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9765\n",
            "Epoch 326/1000\n",
            "16/16 [==============================] - 12s 729ms/step - loss: 1.3056e-04 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9765\n",
            "Epoch 327/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 1.2812e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9765\n",
            "Epoch 328/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 1.3518e-04 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9765\n",
            "Epoch 329/1000\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 1.2184e-04 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9765\n",
            "Epoch 330/1000\n",
            "16/16 [==============================] - 12s 725ms/step - loss: 1.2312e-04 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9765\n",
            "Epoch 331/1000\n",
            "16/16 [==============================] - 12s 726ms/step - loss: 1.2073e-04 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9765\n",
            "Epoch 332/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 1.1953e-04 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9765\n",
            "Epoch 333/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 1.4001e-04 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9765\n",
            "Epoch 334/1000\n",
            "16/16 [==============================] - 12s 726ms/step - loss: 1.1582e-04 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9765\n",
            "Epoch 335/1000\n",
            "16/16 [==============================] - 12s 723ms/step - loss: 1.1596e-04 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9765\n",
            "Epoch 336/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 1.1394e-04 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9765\n",
            "Epoch 337/1000\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 1.1191e-04 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9765\n",
            "Epoch 338/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 1.1102e-04 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9765\n",
            "Epoch 339/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 1.1199e-04 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9765\n",
            "Epoch 340/1000\n",
            "16/16 [==============================] - 12s 738ms/step - loss: 1.0749e-04 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9765\n",
            "Epoch 341/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 1.0793e-04 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9765\n",
            "Epoch 342/1000\n",
            "16/16 [==============================] - 12s 727ms/step - loss: 1.0696e-04 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9765\n",
            "Epoch 343/1000\n",
            "16/16 [==============================] - 12s 738ms/step - loss: 1.2569e-04 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9765\n",
            "Epoch 344/1000\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 1.0508e-04 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9765\n",
            "Epoch 345/1000\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 1.0740e-04 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9765\n",
            "Epoch 346/1000\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 1.6924e-04 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9765\n",
            "Epoch 347/1000\n",
            "16/16 [==============================] - 12s 723ms/step - loss: 1.3890e-04 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9765\n",
            "Epoch 348/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1350e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 148.\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 1.1350e-04 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9765\n",
            "Epoch 348: early stopping\n",
            "7/7 [==============================] - 6s 466ms/step\n",
            "VGG16 done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculation of Accuracy, Sensitivity, Specificity, Precision, Recall and AUC Value"
      ],
      "metadata": {
        "id": "mgPcX-aUEXLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(testPreds2)\n",
        "tp2 = []\n",
        "for i in testPreds2:\n",
        "  if i < 0.5:\n",
        "    tp2.append(0)\n",
        "  else:\n",
        "    tp2.append(1)\n",
        "\n",
        "# print(testPreds3)\n",
        "tp3 = []\n",
        "for i in testPreds3:\n",
        "  if i < 0.5:\n",
        "    tp3.append(0)\n",
        "  else:\n",
        "    tp3.append(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cm = confusion_matrix(yTest, tp2)\n",
        "sensitivity2 = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity2 = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "precision2 = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
        "recall2 = cm[1, 1] / (cm[0, 1] + cm[1, 1])\n",
        "accuracy2 = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0])\n",
        "print(\"\\n\\nFor MobileNet\")\n",
        "print(\"\\n Accuracy: \",accuracy2)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity2)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity2)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision2)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall2)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, tp2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cm = confusion_matrix(yTest, tp3)\n",
        "sensitivity3 = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity3 = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "precision3 = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
        "recall3 = cm[1, 1] / (cm[0, 1] + cm[1, 1])\n",
        "accuracy3 = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0])\n",
        "print(\"\\n\\nFor VGG16\")\n",
        "print(\"\\n Accuracy: \",accuracy3)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity3)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity3)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision3)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall3)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, tp3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_VQtctCXj9_",
        "outputId": "f29a4d82-bf58-4b19-efe5-6ea76d0d8c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "For MobileNet\n",
            "\n",
            " Accuracy:  0.9620853080568721\n",
            "\n",
            "\n",
            " Sensitivity:  0.9680851063829787\n",
            "\n",
            "\n",
            " Specificity:  0.9572649572649573\n",
            "\n",
            "\n",
            " Precision:  0.9479166666666666\n",
            "\n",
            "\n",
            " Recall:  0.9739130434782609\n",
            "\n",
            "AUC Value:  0.9626750318239681\n",
            "\n",
            "\n",
            "For VGG16\n",
            "\n",
            " Accuracy:  0.966824644549763\n",
            "\n",
            "\n",
            " Sensitivity:  0.9468085106382979\n",
            "\n",
            "\n",
            " Specificity:  0.9829059829059829\n",
            "\n",
            "\n",
            " Precision:  0.978021978021978\n",
            "\n",
            "\n",
            " Recall:  0.9583333333333334\n",
            "\n",
            "AUC Value:  0.9648572467721405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix for MobileNet"
      ],
      "metadata": {
        "id": "mp8R6uvwDsBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "class_labels = [\"Abnormal(Ulcer)\",\"Normal(Healthy skin)\"]\n",
        "from sklearn.metrics import confusion_matrix\n",
        "plt.figure(figsize=(16,9))\n",
        "y_pred_labels = [ np.argmax(label) for label in testPreds2]\n",
        "cm = confusion_matrix(yTest, tp2)\n",
        "sns.heatmap(cm, annot = True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)"
      ],
      "metadata": {
        "id": "HVbKf6bigfdx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "08275a8e-511f-450a-f76b-ffa82c6742d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix for VGG16"
      ],
      "metadata": {
        "id": "oK8o-UnKs1yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "y_pred_labels = [ np.argmax(label) for label in testPreds3]\n",
        "cm = confusion_matrix(yTest, tp3)\n",
        "sns.heatmap(cm, annot = True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)"
      ],
      "metadata": {
        "id": "6o0h9PVOgl1-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "da9fd5ec-2e01-4739-ea18-f5252e4dd9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate F1 Score"
      ],
      "metadata": {
        "id": "SFPh8q6ADzMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score2 = 2 * (precision2 * recall2) / (precision2 + recall2)\n",
        "# f1 = f1_score(yTest, testPreds1)\n",
        "print(f1_score2)\n",
        "\n",
        "f1_score3 = 2 * (precision3 * recall3) / (precision3 + recall3)\n",
        "# f1 = f1_score(yTest, testPreds1)\n",
        "print(f1_score3)\n"
      ],
      "metadata": {
        "id": "8B6S4Yz413CD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c45dac7-18f4-4bf0-fa22-4bb5e5407dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9607390300230947\n",
            "0.9680775597067864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification Report"
      ],
      "metadata": {
        "id": "sF1Hf30kD38l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "table = [['Model Name','Accuracy','Sensitivity','Specificity', 'Precision', 'Recall','F1 Score', 'AUC Value'],\n",
        "\n",
        "         ['MobileNet', accuracy2, sensitivity2, specificity2, precision2, recall2,f1_score2, roc_auc_score(yTest, tp2)],\n",
        "         ['VGG16',accuracy3, sensitivity3, specificity3, precision3, recall3,f1_score3, roc_auc_score(yTest, tp3)]]\n",
        "\n",
        "print(tabulate(table, headers='firstrow', tablefmt='grid'))"
      ],
      "metadata": {
        "id": "9xYKRg7HvHvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230a8ce2-d435-49ba-af3f-6f4721f8e997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+---------------+---------------+-------------+----------+------------+-------------+\n",
            "| Model Name   |   Accuracy |   Sensitivity |   Specificity |   Precision |   Recall |   F1 Score |   AUC Value |\n",
            "+==============+============+===============+===============+=============+==========+============+=============+\n",
            "| MobileNet    |   0.962085 |      0.968085 |      0.957265 |    0.947917 | 0.973913 |   0.960739 |    0.962675 |\n",
            "+--------------+------------+---------------+---------------+-------------+----------+------------+-------------+\n",
            "| VGG16        |   0.966825 |      0.946809 |      0.982906 |    0.978022 | 0.958333 |   0.968078 |    0.964857 |\n",
            "+--------------+------------+---------------+---------------+-------------+----------+------------+-------------+\n"
          ]
        }
      ]
    }
  ]
}