{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asP3yxpdpQV"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import random\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "import warnings\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LwfnDV3eguR"
      },
      "source": [
        "def load_images_from_folder(folder):\n",
        "\timages = []\n",
        "\tdirs = os.listdir(folder)\n",
        "\n",
        "\tfor filename in dirs:\n",
        "\t\tif os.path.isfile(folder+filename):\n",
        "\t\t\tim = Image.open(folder+filename)\n",
        "\t\t\timResize = im.resize((224,224), Image.ANTIALIAS)\n",
        "\t\t\timResize = np.array(imResize)\n",
        "\t\t\tif imResize is not None:\n",
        "\t\t\t\timages.append(imResize)\n",
        "\treturn images\n",
        "\n",
        "\n",
        "def prepareData(parentPath):\n",
        "\n",
        "\t# Make a list of all the 0 label and 1 label images for train, val, and test sets\n",
        "\n",
        "\tall0_path = list()\n",
        "\n",
        "\n",
        "\tall1_path = list()\n",
        "\n",
        "\n",
        "\tall0_path.append(parentPath+'/Abnormal(Ulcer)/')\n",
        "\tall1_path.append(parentPath+'/Normal(Healthy skin)/')\n",
        "\n",
        "\n",
        "\t# Read images into respective lists\n",
        "\n",
        "\n",
        "\tallX = list()\n",
        "\tallY = list()\n",
        "\txTrain = list()\n",
        "\tyTrain = list()\n",
        "\txVal = list()\n",
        "\tyVal = list()\n",
        "\txTest = list()\n",
        "\tyTest = list()\n",
        "\n",
        "\t# Prepare all data for 0 class\n",
        "\tprint('\\n\\n Class Abnormal(Ulcer), reading started..\\n\\n')\n",
        "\n",
        "\n",
        "\ttempImgs = list()\n",
        "\ttempImgs = load_images_from_folder(all0_path[0])\n",
        "\tfor i in range(len(tempImgs)):\n",
        "\t\tallX.append(tempImgs[i])\n",
        "\t\tallY.append(0)\n",
        "\n",
        "\t# Prepare all data for 1 class\n",
        "\tprint('\\n\\n Class Normal(Healthy skin), reading started..\\n\\n')\n",
        "\ttempImgs = list()\n",
        "\ttempImgs = load_images_from_folder(all1_path[0])\n",
        "\tfor i in range(len(tempImgs)):\n",
        "\t\tallX.append(tempImgs[i])\n",
        "\t\tallY.append(1)\n",
        "\n",
        "\txTrain,xTest,yTrain,yTest = train_test_split(allX,allY, test_size=0.20, random_state=10, shuffle = True)\n",
        "\n",
        "\txpTrain,xVal,ypTrain,yVal = train_test_split(xTrain,yTrain, test_size=0.10, random_state=10, shuffle = True)\n",
        "\n",
        "\treturn xpTrain, ypTrain, xVal, yVal, xTest, yTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DenseNet"
      ],
      "metadata": {
        "id": "EyPm7VODGRmD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQJ4-AAE8RJ2"
      },
      "source": [
        "from keras.applications.densenet import DenseNet121\n",
        "def DenseNet121_transfer_actual(input_shape):\n",
        "  res = DenseNet121(weights=None, include_top=False, input_shape=input_shape)\n",
        "  for layers in res.layers:\n",
        "    layers.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(res)\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  ## The following is the vanilla VGG16 architecture's FC layers\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=1000,activation=\"relu\"))\n",
        "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet"
      ],
      "metadata": {
        "id": "eVbp6L0zGNjY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOcg_1NYqJz3"
      },
      "source": [
        "from keras.applications.resnet import ResNet50\n",
        "def ResNet50_transfer_actual(input_shape):\n",
        "  res = ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
        "  for layers in res.layers:\n",
        "    layers.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(res)\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  ## The following is the vanilla VGG16 architecture's FC layers\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=1000,activation=\"relu\"))\n",
        "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "InceptionV3"
      ],
      "metadata": {
        "id": "QSfrcP8IGJ17"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdRx35RP0VjD"
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "def InceptionV3_transfer_actual(input_shape):\n",
        "  res = InceptionV3(weights=None, include_top=False, input_shape=input_shape)\n",
        "  for layers in res.layers:\n",
        "    layers.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(res)\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  ## The following is the vanilla VGG16 architecture's FC layers\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=1000,activation=\"relu\"))\n",
        "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWzwMmrHKEry"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auroc(y_true, y_pred):\n",
        "  return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing dataset from google drive"
      ],
      "metadata": {
        "id": "98NIG_WMFnej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "parentPath='/content/drive/MyDrive/DFU/Patches'\n",
        "xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(parentPath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lv4GgX7sj3h",
        "outputId": "64174b7d-28fd-4f4a-c8fb-38a4e7a6f516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "\n",
            " Class Abnormal(Ulcer), reading started..\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Class Normal(Healthy skin), reading started..\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0mk9-MC8VRb"
      },
      "source": [
        "xTrain = np.array(xTrain)\n",
        "yTrain = np.array(yTrain)\n",
        "xVal = np.array(xVal)\n",
        "yVal = np.array(yVal)\n",
        "xTest = np.array(xTest)\n",
        "yTest = np.array(yTest)\n",
        "\n",
        "# Prepare the data\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "  input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "  input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "xTrain = xTrain / 255\n",
        "xVal = xVal / 255\n",
        "xTest = xTest / 255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking shape of Training, Validation and Test data"
      ],
      "metadata": {
        "id": "m_-az6ciE0NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(xTrain.shape)\n",
        "print(xVal.shape)\n",
        "print(xTest.shape)"
      ],
      "metadata": {
        "id": "hoyuCOyw2cCj",
        "outputId": "61d38b1b-ed29-491c-c370-26ac797c8b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(759, 224, 224, 3)\n",
            "(85, 224, 224, 3)\n",
            "(211, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xwWqHyPhQ_F"
      },
      "source": [
        "testPreds1 , testPreds2 , testPreds3 = 0 , 0 , 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Model"
      ],
      "metadata": {
        "id": "EPPMSMQJEvQl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL8BAkLUZJWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a482bd86-864b-4da5-aa9f-0299263e233f"
      },
      "source": [
        "model1 = InceptionV3_transfer_actual(input_shape)\n",
        "# model1 = ResNet50_transfer_actual(input_shape)\n",
        "# model1 = DenseNet121_transfer_actual(input_shape)\n",
        "\n",
        "  ## Train Model\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200, restore_best_weights=True)\n",
        "model1.fit(xTrain, yTrain, epochs=1000, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "#model2.fit(xTrain, yTrain, epochs=10, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "#model3.fit(xTrain, yTrain, epochs=10, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "testPreds1 = model1.predict(xTest)\n",
        "print(\"Inception Done\")\n",
        "\n",
        "model1 = ResNet50_transfer_actual(input_shape)\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200, restore_best_weights=True)\n",
        "model1.fit(xTrain, yTrain, epochs=1000, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "testPreds2 = model1.predict(xTest)\n",
        "print(\"resnet done\")\n",
        "\n",
        "model1 = DenseNet121_transfer_actual(input_shape)\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200, restore_best_weights=True)\n",
        "model1.fit(xTrain, yTrain, epochs=1000, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "testPreds3 = model1.predict(xTest)\n",
        "print(\"densenet done.\")\n",
        "\n",
        "#model1.save('inception_v3.h5')\n",
        "#model2.save('resnet_50.h5')\n",
        "#model3.save('densenet121.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 51200)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              209719296 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              4097000   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 1001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 252,401,393\n",
            "Trainable params: 252,366,961\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "16/16 [==============================] - 32s 857ms/step - loss: 0.5626 - accuracy: 0.6864 - val_loss: 0.6946 - val_accuracy: 0.5176\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 6s 397ms/step - loss: 0.3908 - accuracy: 0.8419 - val_loss: 0.6970 - val_accuracy: 0.5176\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 0.2769 - accuracy: 0.8893 - val_loss: 0.7198 - val_accuracy: 0.5059\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 0.2172 - accuracy: 0.9262 - val_loss: 0.9536 - val_accuracy: 0.5176\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 0.1367 - accuracy: 0.9578 - val_loss: 1.2660 - val_accuracy: 0.5176\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 6s 404ms/step - loss: 0.1703 - accuracy: 0.9368 - val_loss: 1.4276 - val_accuracy: 0.5176\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 6s 405ms/step - loss: 0.1744 - accuracy: 0.9420 - val_loss: 1.6509 - val_accuracy: 0.5176\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 0.1128 - accuracy: 0.9644 - val_loss: 1.9360 - val_accuracy: 0.5176\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 0.1022 - accuracy: 0.9657 - val_loss: 2.3650 - val_accuracy: 0.5176\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 0.0938 - accuracy: 0.9723 - val_loss: 2.6554 - val_accuracy: 0.5176\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 7s 411ms/step - loss: 0.0835 - accuracy: 0.9736 - val_loss: 2.9047 - val_accuracy: 0.5176\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 7s 412ms/step - loss: 0.1120 - accuracy: 0.9578 - val_loss: 3.1015 - val_accuracy: 0.5176\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 0.1317 - accuracy: 0.9592 - val_loss: 3.1278 - val_accuracy: 0.5176\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 0.1603 - accuracy: 0.9473 - val_loss: 2.7831 - val_accuracy: 0.5176\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 0.0988 - accuracy: 0.9671 - val_loss: 2.8605 - val_accuracy: 0.5176\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 0.0740 - accuracy: 0.9763 - val_loss: 3.2113 - val_accuracy: 0.5176\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 0.0825 - accuracy: 0.9723 - val_loss: 2.9723 - val_accuracy: 0.5176\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 0.0757 - accuracy: 0.9684 - val_loss: 3.0933 - val_accuracy: 0.5176\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 7s 458ms/step - loss: 0.0841 - accuracy: 0.9697 - val_loss: 2.2340 - val_accuracy: 0.5412\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 7s 463ms/step - loss: 0.0712 - accuracy: 0.9697 - val_loss: 1.8582 - val_accuracy: 0.5647\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 7s 462ms/step - loss: 0.1624 - accuracy: 0.9460 - val_loss: 0.7827 - val_accuracy: 0.7647\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 0.0964 - accuracy: 0.9618 - val_loss: 1.0882 - val_accuracy: 0.6706\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 7s 423ms/step - loss: 0.0660 - accuracy: 0.9816 - val_loss: 0.7934 - val_accuracy: 0.7647\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 7s 459ms/step - loss: 0.0915 - accuracy: 0.9723 - val_loss: 0.6337 - val_accuracy: 0.7882\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 7s 423ms/step - loss: 0.0602 - accuracy: 0.9789 - val_loss: 0.6450 - val_accuracy: 0.7882\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 7s 464ms/step - loss: 0.0375 - accuracy: 0.9868 - val_loss: 0.5806 - val_accuracy: 0.8000\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 7s 466ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.2446 - val_accuracy: 0.8941\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 0.0727 - accuracy: 0.9736 - val_loss: 0.2794 - val_accuracy: 0.8706\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 7s 467ms/step - loss: 0.0611 - accuracy: 0.9868 - val_loss: 0.1681 - val_accuracy: 0.9529\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 0.0355 - accuracy: 0.9855 - val_loss: 0.1770 - val_accuracy: 0.9412\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 0.0890 - accuracy: 0.9631 - val_loss: 0.2582 - val_accuracy: 0.9176\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 7s 428ms/step - loss: 0.0546 - accuracy: 0.9842 - val_loss: 0.1250 - val_accuracy: 0.9529\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 0.0222 - accuracy: 0.9934 - val_loss: 0.1232 - val_accuracy: 0.9529\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 7s 466ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 0.1131 - val_accuracy: 0.9647\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0308 - accuracy: 0.9881 - val_loss: 0.0856 - val_accuracy: 0.9647\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.1187 - val_accuracy: 0.9647\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 8s 471ms/step - loss: 0.1026 - accuracy: 0.9592 - val_loss: 0.0912 - val_accuracy: 0.9765\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0746 - accuracy: 0.9763 - val_loss: 0.1599 - val_accuracy: 0.9647\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.1210 - val_accuracy: 0.9529\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0290 - accuracy: 0.9895 - val_loss: 0.1130 - val_accuracy: 0.9529\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 7s 439ms/step - loss: 0.0263 - accuracy: 0.9868 - val_loss: 0.1058 - val_accuracy: 0.9529\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.0866 - val_accuracy: 0.9765\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.0836 - val_accuracy: 0.9765\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 0.1626 - val_accuracy: 0.9529\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0699 - accuracy: 0.9802 - val_loss: 0.1053 - val_accuracy: 0.9647\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.1594 - accuracy: 0.9328 - val_loss: 0.5869 - val_accuracy: 0.8471\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 0.1148 - accuracy: 0.9565 - val_loss: 0.2515 - val_accuracy: 0.9294\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0861 - accuracy: 0.9736 - val_loss: 0.2032 - val_accuracy: 0.9294\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0563 - accuracy: 0.9776 - val_loss: 0.1299 - val_accuracy: 0.9529\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0488 - accuracy: 0.9868 - val_loss: 0.1264 - val_accuracy: 0.9294\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0292 - accuracy: 0.9855 - val_loss: 0.1077 - val_accuracy: 0.9647\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.0852 - val_accuracy: 0.9765\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0249 - accuracy: 0.9895 - val_loss: 0.0902 - val_accuracy: 0.9765\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 7s 467ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0886 - val_accuracy: 0.9882\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0727 - val_accuracy: 0.9882\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.0745 - val_accuracy: 0.9882\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0691 - val_accuracy: 0.9882\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.0764 - val_accuracy: 0.9765\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0501 - accuracy: 0.9908 - val_loss: 0.0403 - val_accuracy: 0.9765\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0489 - val_accuracy: 0.9647\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.0356 - val_accuracy: 0.9882\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 0.0639 - accuracy: 0.9868 - val_loss: 0.0728 - val_accuracy: 0.9882\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.0733 - val_accuracy: 0.9765\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0655 - val_accuracy: 0.9647\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0325 - accuracy: 0.9868 - val_loss: 0.0669 - val_accuracy: 0.9647\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 0.0087 - accuracy: 0.9987 - val_loss: 0.0709 - val_accuracy: 0.9647\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0594 - val_accuracy: 0.9765\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0557 - val_accuracy: 0.9765\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9765\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 0.0108 - accuracy: 0.9947 - val_loss: 0.0831 - val_accuracy: 0.9647\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 0.1109 - val_accuracy: 0.9647\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 0.1069 - accuracy: 0.9750 - val_loss: 0.2050 - val_accuracy: 0.9412\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0583 - accuracy: 0.9789 - val_loss: 0.0708 - val_accuracy: 0.9765\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 0.0595 - accuracy: 0.9776 - val_loss: 0.0882 - val_accuracy: 0.9647\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0566 - val_accuracy: 0.9765\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 0.0630 - accuracy: 0.9789 - val_loss: 0.3963 - val_accuracy: 0.9412\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0308 - accuracy: 0.9934 - val_loss: 0.1771 - val_accuracy: 0.9529\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.0506 - val_accuracy: 0.9647\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0817 - val_accuracy: 0.9647\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0112 - accuracy: 0.9947 - val_loss: 0.0951 - val_accuracy: 0.9529\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0819 - val_accuracy: 0.9529\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0279 - accuracy: 0.9895 - val_loss: 0.0667 - val_accuracy: 0.9765\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0445 - accuracy: 0.9855 - val_loss: 0.0549 - val_accuracy: 0.9765\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0425 - accuracy: 0.9816 - val_loss: 0.0637 - val_accuracy: 0.9765\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.0949 - val_accuracy: 0.9647\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.1027 - val_accuracy: 0.9647\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.0681 - val_accuracy: 0.9882\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0789 - val_accuracy: 0.9882\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 0.0316 - accuracy: 0.9895 - val_loss: 0.1089 - val_accuracy: 0.9529\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0325 - accuracy: 0.9934 - val_loss: 0.1076 - val_accuracy: 0.9529\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0258 - accuracy: 0.9895 - val_loss: 0.5617 - val_accuracy: 0.8706\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0808 - val_accuracy: 0.9765\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0898 - val_accuracy: 0.9647\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.3552 - val_accuracy: 0.9176\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0813 - val_accuracy: 0.9765\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0646 - val_accuracy: 0.9765\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0555 - val_accuracy: 0.9765\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.0492 - val_accuracy: 0.9765\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.0540 - val_accuracy: 0.9765\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.0291 - val_accuracy: 0.9882\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0435 - val_accuracy: 0.9765\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9765\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9529\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9529\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1034 - val_accuracy: 0.9647\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0466 - accuracy: 0.9802 - val_loss: 0.1271 - val_accuracy: 0.9529\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0217 - accuracy: 0.9895 - val_loss: 0.2729 - val_accuracy: 0.9412\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0333 - accuracy: 0.9921 - val_loss: 0.2190 - val_accuracy: 0.9647\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.1509 - val_accuracy: 0.9647\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1316 - val_accuracy: 0.9647\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1197 - val_accuracy: 0.9647\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0884 - val_accuracy: 0.9765\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0887 - val_accuracy: 0.9765\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0347 - accuracy: 0.9921 - val_loss: 0.1540 - val_accuracy: 0.9412\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1569 - val_accuracy: 0.9294\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9529\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.1540 - val_accuracy: 0.9647\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.1289 - val_accuracy: 0.9647\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1012 - val_accuracy: 0.9647\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.1097 - val_accuracy: 0.9647\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.1003 - val_accuracy: 0.9647\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0624 - accuracy: 0.9816 - val_loss: 0.2874 - val_accuracy: 0.9529\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0475 - accuracy: 0.9855 - val_loss: 0.0690 - val_accuracy: 0.9765\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0685 - accuracy: 0.9802 - val_loss: 0.0947 - val_accuracy: 0.9765\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0226 - accuracy: 0.9908 - val_loss: 0.0976 - val_accuracy: 0.9647\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0271 - accuracy: 0.9895 - val_loss: 0.1967 - val_accuracy: 0.9529\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0293 - accuracy: 0.9868 - val_loss: 0.0718 - val_accuracy: 0.9882\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0736 - val_accuracy: 0.9765\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.0767 - val_accuracy: 0.9765\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.1241 - val_accuracy: 0.9647\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0311 - accuracy: 0.9895 - val_loss: 0.0725 - val_accuracy: 0.9765\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0869 - val_accuracy: 0.9765\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.0838 - val_accuracy: 0.9765\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9765\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0786 - val_accuracy: 0.9765\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.0616 - val_accuracy: 0.9765\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0367 - accuracy: 0.9842 - val_loss: 0.0894 - val_accuracy: 0.9529\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0136 - accuracy: 0.9934 - val_loss: 0.0831 - val_accuracy: 0.9765\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0081 - accuracy: 0.9960 - val_loss: 0.0703 - val_accuracy: 0.9765\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0655 - val_accuracy: 0.9765\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.0781 - val_accuracy: 0.9765\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.1013 - val_accuracy: 0.9529\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.0769 - val_accuracy: 0.9765\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.0763 - val_accuracy: 0.9765\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0717 - val_accuracy: 0.9765\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0738 - val_accuracy: 0.9765\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0075 - accuracy: 0.9960 - val_loss: 0.1263 - val_accuracy: 0.9647\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 7s 438ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.1000 - val_accuracy: 0.9765\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1028 - val_accuracy: 0.9647\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9765\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.0960 - val_accuracy: 0.9412\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0267 - accuracy: 0.9895 - val_loss: 0.0987 - val_accuracy: 0.9529\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0362 - accuracy: 0.9934 - val_loss: 0.1344 - val_accuracy: 0.9529\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.1529 - val_accuracy: 0.9529\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.1010 - val_accuracy: 0.9647\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0173 - accuracy: 0.9934 - val_loss: 0.1643 - val_accuracy: 0.9294\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.3286 - val_accuracy: 0.9294\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.1761 - val_accuracy: 0.9412\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 0.3196 - val_accuracy: 0.9059\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0372 - accuracy: 0.9816 - val_loss: 0.1318 - val_accuracy: 0.9412\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.1161 - val_accuracy: 0.9765\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.1139 - val_accuracy: 0.9765\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0085 - accuracy: 0.9960 - val_loss: 0.1084 - val_accuracy: 0.9765\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.1108 - val_accuracy: 0.9765\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.1115 - val_accuracy: 0.9765\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9765\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9765\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1080 - val_accuracy: 0.9765\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.1107 - val_accuracy: 0.9765\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9529\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.1141 - val_accuracy: 0.9765\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 0.0273 - accuracy: 0.9881 - val_loss: 0.2614 - val_accuracy: 0.9176\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.3052 - val_accuracy: 0.9176\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 0.0201 - accuracy: 0.9895 - val_loss: 0.1930 - val_accuracy: 0.9412\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9765\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0893 - val_accuracy: 0.9412\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9294\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9765\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.1129 - val_accuracy: 0.9647\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0553 - val_accuracy: 0.9882\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.0559 - val_accuracy: 0.9765\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.1318 - val_accuracy: 0.9529\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.0901 - val_accuracy: 0.9529\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0088 - accuracy: 0.9960 - val_loss: 0.0898 - val_accuracy: 0.9529\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9529\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0835 - val_accuracy: 0.9529\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.0788 - val_accuracy: 0.9765\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0739 - val_accuracy: 0.9765\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0567 - val_accuracy: 0.9647\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.0527 - val_accuracy: 0.9882\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0693 - val_accuracy: 0.9765\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0614 - val_accuracy: 0.9765\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0605 - val_accuracy: 0.9765\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9765\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0647 - val_accuracy: 0.9765\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0660 - val_accuracy: 0.9765\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0874 - val_accuracy: 0.9529\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0783 - accuracy: 0.9710 - val_loss: 0.1109 - val_accuracy: 0.9529\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0447 - accuracy: 0.9829 - val_loss: 0.0903 - val_accuracy: 0.9765\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0431 - accuracy: 0.9842 - val_loss: 0.1132 - val_accuracy: 0.9765\n",
            "Epoch 201/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0324 - accuracy: 0.9868 - val_loss: 0.1106 - val_accuracy: 0.9765\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.1052 - val_accuracy: 0.9765\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.1096 - val_accuracy: 0.9765\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.1003 - val_accuracy: 0.9765\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0176 - accuracy: 0.9934 - val_loss: 0.0897 - val_accuracy: 0.9765\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0976 - val_accuracy: 0.9765\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 0.1048 - val_accuracy: 0.9765\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1057 - val_accuracy: 0.9765\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0174 - accuracy: 0.9921 - val_loss: 0.1027 - val_accuracy: 0.9765\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0552 - accuracy: 0.9868 - val_loss: 0.1164 - val_accuracy: 0.9647\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 0.1578 - val_accuracy: 0.9647\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 0.1354 - val_accuracy: 0.9765\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.1239 - val_accuracy: 0.9765\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.1240 - val_accuracy: 0.9765\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0374 - accuracy: 0.9921 - val_loss: 0.1006 - val_accuracy: 0.9765\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0632 - accuracy: 0.9802 - val_loss: 0.1707 - val_accuracy: 0.9412\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0254 - accuracy: 0.9908 - val_loss: 0.0781 - val_accuracy: 0.9765\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0247 - accuracy: 0.9881 - val_loss: 0.0863 - val_accuracy: 0.9765\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0112 - accuracy: 0.9947 - val_loss: 0.0962 - val_accuracy: 0.9647\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9647\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 0.0160 - accuracy: 0.9987 - val_loss: 0.0894 - val_accuracy: 0.9765\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0988 - val_accuracy: 0.9647\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0091 - accuracy: 0.9960 - val_loss: 0.0911 - val_accuracy: 0.9647\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1025 - val_accuracy: 0.9647\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9647\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9882\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.0849 - val_accuracy: 0.9765\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.0725 - val_accuracy: 0.9765\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9882\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.0701 - val_accuracy: 0.9882\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0864 - val_accuracy: 0.9882\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.1015 - val_accuracy: 0.9882\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1282 - val_accuracy: 0.9647\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 0.1383 - val_accuracy: 0.9765\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.1436 - val_accuracy: 0.9765\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.1544 - val_accuracy: 0.9765\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1356 - val_accuracy: 0.9765\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0203 - accuracy: 0.9908 - val_loss: 0.1510 - val_accuracy: 0.9765\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.1350 - val_accuracy: 0.9765\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0288 - accuracy: 0.9895 - val_loss: 0.1967 - val_accuracy: 0.9412\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0180 - accuracy: 0.9960 - val_loss: 0.1489 - val_accuracy: 0.9647\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.1042 - val_accuracy: 0.9765\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0880 - val_accuracy: 0.9882\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 0.0233 - accuracy: 0.9868 - val_loss: 0.0911 - val_accuracy: 0.9882\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.1064 - val_accuracy: 0.9765\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.1359 - val_accuracy: 0.9647\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.1007 - val_accuracy: 0.9529\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0832 - val_accuracy: 0.9765\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.1014 - val_accuracy: 0.9765\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0282 - accuracy: 0.9934 - val_loss: 0.1320 - val_accuracy: 0.9647\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.1032 - val_accuracy: 0.9647\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.0966 - val_accuracy: 0.9765\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9765\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 54.\n",
            "16/16 [==============================] - 7s 457ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9765\n",
            "Epoch 254: early stopping\n",
            "7/7 [==============================] - 4s 236ms/step\n",
            "Inception Done\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              411045888 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1000)              4097000   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 1001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 455,512,913\n",
            "Trainable params: 455,459,793\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "16/16 [==============================] - 26s 1s/step - loss: 0.6678 - accuracy: 0.7339 - val_loss: 2.3863 - val_accuracy: 0.4824\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.4858 - accuracy: 0.7866 - val_loss: 1.0888 - val_accuracy: 0.4824\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 11s 668ms/step - loss: 0.3440 - accuracy: 0.8551 - val_loss: 0.9499 - val_accuracy: 0.5765\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 10s 658ms/step - loss: 0.4503 - accuracy: 0.8432 - val_loss: 0.7262 - val_accuracy: 0.5882\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 11s 664ms/step - loss: 0.2966 - accuracy: 0.8748 - val_loss: 0.6883 - val_accuracy: 0.6353\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 0.1967 - accuracy: 0.9223 - val_loss: 0.8526 - val_accuracy: 0.5647\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 0.1710 - accuracy: 0.9302 - val_loss: 1.3754 - val_accuracy: 0.5059\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 9s 587ms/step - loss: 0.1656 - accuracy: 0.9473 - val_loss: 2.1627 - val_accuracy: 0.5176\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.2073 - accuracy: 0.9262 - val_loss: 1.9987 - val_accuracy: 0.5176\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.1575 - accuracy: 0.9354 - val_loss: 2.2845 - val_accuracy: 0.5176\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 9s 587ms/step - loss: 0.0742 - accuracy: 0.9723 - val_loss: 2.8754 - val_accuracy: 0.5176\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0496 - accuracy: 0.9802 - val_loss: 3.5209 - val_accuracy: 0.5176\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 3.8267 - val_accuracy: 0.5176\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0510 - accuracy: 0.9789 - val_loss: 4.1615 - val_accuracy: 0.5176\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0330 - accuracy: 0.9855 - val_loss: 4.6380 - val_accuracy: 0.5176\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 10s 615ms/step - loss: 0.0908 - accuracy: 0.9750 - val_loss: 4.4549 - val_accuracy: 0.5176\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0771 - accuracy: 0.9763 - val_loss: 3.9629 - val_accuracy: 0.5412\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 2.9499 - val_accuracy: 0.5765\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 2.3567 - val_accuracy: 0.6353\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.1038 - accuracy: 0.9578 - val_loss: 1.5912 - val_accuracy: 0.6118\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0508 - accuracy: 0.9829 - val_loss: 1.6731 - val_accuracy: 0.6235\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 10s 655ms/step - loss: 0.0488 - accuracy: 0.9763 - val_loss: 1.6790 - val_accuracy: 0.6588\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 11s 662ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 1.5369 - val_accuracy: 0.7059\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0482 - accuracy: 0.9842 - val_loss: 1.9269 - val_accuracy: 0.7059\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 10s 658ms/step - loss: 0.0899 - accuracy: 0.9710 - val_loss: 0.2433 - val_accuracy: 0.8941\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.1047 - accuracy: 0.9736 - val_loss: 0.4461 - val_accuracy: 0.8706\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 11s 663ms/step - loss: 0.0480 - accuracy: 0.9868 - val_loss: 0.2042 - val_accuracy: 0.9176\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.1342 - accuracy: 0.9486 - val_loss: 1.7546 - val_accuracy: 0.7882\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0469 - accuracy: 0.9842 - val_loss: 0.2947 - val_accuracy: 0.9059\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0301 - accuracy: 0.9881 - val_loss: 0.2607 - val_accuracy: 0.9176\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 10s 654ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.1472 - val_accuracy: 0.9529\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0851 - accuracy: 0.9697 - val_loss: 0.3285 - val_accuracy: 0.8824\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0316 - accuracy: 0.9881 - val_loss: 0.3111 - val_accuracy: 0.8706\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.2271 - val_accuracy: 0.9294\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 0.1716 - val_accuracy: 0.9529\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9529\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 11s 662ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.1042 - val_accuracy: 0.9647\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0535 - accuracy: 0.9802 - val_loss: 0.4303 - val_accuracy: 0.9059\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 9s 587ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.1148 - val_accuracy: 0.9647\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0688 - accuracy: 0.9789 - val_loss: 0.9671 - val_accuracy: 0.8824\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0268 - accuracy: 0.9881 - val_loss: 0.2768 - val_accuracy: 0.9294\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0402 - accuracy: 0.9842 - val_loss: 0.3251 - val_accuracy: 0.9294\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.1032 - val_accuracy: 0.9647\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0187 - accuracy: 0.9908 - val_loss: 0.1781 - val_accuracy: 0.9412\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0286 - accuracy: 0.9895 - val_loss: 0.1934 - val_accuracy: 0.9412\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 10s 654ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.0830 - val_accuracy: 0.9765\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.1046 - val_accuracy: 0.9765\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.1262 - val_accuracy: 0.9765\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.1016 - val_accuracy: 0.9765\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0296 - accuracy: 0.9881 - val_loss: 0.1619 - val_accuracy: 0.9529\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.2063 - val_accuracy: 0.9412\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.2000 - val_accuracy: 0.9529\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.1644 - val_accuracy: 0.9529\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9529\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9529\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9529\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 9.4704e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9529\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 0.1668 - val_accuracy: 0.9529\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.1752 - val_accuracy: 0.9529\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0081 - accuracy: 0.9960 - val_loss: 0.1401 - val_accuracy: 0.9765\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.0774 - val_accuracy: 0.9765\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0098 - accuracy: 0.9934 - val_loss: 0.1627 - val_accuracy: 0.9647\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0140 - accuracy: 0.9934 - val_loss: 0.1174 - val_accuracy: 0.9647\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 10s 613ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.1267 - val_accuracy: 0.9765\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.1396 - val_accuracy: 0.9765\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 5.8018e-04 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9765\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0155 - accuracy: 0.9934 - val_loss: 0.1852 - val_accuracy: 0.9647\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.1122 - val_accuracy: 0.9765\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1064 - val_accuracy: 0.9765\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.0898 - val_accuracy: 0.9765\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0326 - accuracy: 0.9868 - val_loss: 0.1420 - val_accuracy: 0.9529\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0625 - accuracy: 0.9816 - val_loss: 0.1871 - val_accuracy: 0.9294\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0989 - accuracy: 0.9736 - val_loss: 1.2255 - val_accuracy: 0.9176\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 0.2618 - val_accuracy: 0.9412\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.2650 - val_accuracy: 0.9412\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.1625 - val_accuracy: 0.9647\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.1426 - val_accuracy: 0.9765\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.1574 - val_accuracy: 0.9765\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.1723 - val_accuracy: 0.9647\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0806 - accuracy: 0.9750 - val_loss: 0.2364 - val_accuracy: 0.9529\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 0.3244 - val_accuracy: 0.9059\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0104 - accuracy: 0.9960 - val_loss: 0.2115 - val_accuracy: 0.9529\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.2034 - val_accuracy: 0.9412\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9647\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1975 - val_accuracy: 0.9647\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1629 - val_accuracy: 0.9765\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.1610 - val_accuracy: 0.9765\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0317 - accuracy: 0.9908 - val_loss: 0.2405 - val_accuracy: 0.9529\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.1845 - val_accuracy: 0.9647\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0364 - accuracy: 0.9868 - val_loss: 0.1747 - val_accuracy: 0.9647\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 10s 612ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.1843 - val_accuracy: 0.9529\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.1311 - val_accuracy: 0.9765\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1524 - val_accuracy: 0.9647\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1508 - val_accuracy: 0.9765\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 9.6514e-04 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9765\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9765\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 6.6199e-04 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9765\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 9.7839e-04 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9765\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 5.3663e-04 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9765\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 7.7985e-04 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9765\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 7.4466e-04 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9765\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.1435 - val_accuracy: 0.9765\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.1557 - val_accuracy: 0.9647\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 4.8957e-04 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9765\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0037 - accuracy: 0.9974 - val_loss: 0.1694 - val_accuracy: 0.9765\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.1973 - val_accuracy: 0.9765\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 0.1940 - val_accuracy: 0.9765\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 6.8423e-04 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9765\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0048 - accuracy: 0.9974 - val_loss: 0.1964 - val_accuracy: 0.9765\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0111 - accuracy: 0.9947 - val_loss: 0.1661 - val_accuracy: 0.9765\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 0.2363 - val_accuracy: 0.9647\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 7.6608e-04 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9529\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0060 - accuracy: 0.9960 - val_loss: 0.2403 - val_accuracy: 0.9647\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9765\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9765\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.2288 - val_accuracy: 0.9765\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.2287 - val_accuracy: 0.9765\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 0.2190 - val_accuracy: 0.9765\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.2201 - val_accuracy: 0.9765\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.2115 - val_accuracy: 0.9765\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 3.3234e-04 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9647\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.8182e-04 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9647\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.7144e-04 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9647\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 5.1723e-04 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9647\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.9844e-04 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9647\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 3.6700e-04 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9647\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.2106 - val_accuracy: 0.9647\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.2084 - val_accuracy: 0.9647\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.5088 - val_accuracy: 0.9059\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.3455 - val_accuracy: 0.9059\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.1947 - val_accuracy: 0.9647\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.2827 - val_accuracy: 0.9176\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 0.1626 - val_accuracy: 0.9647\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9647\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9647\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.1144 - val_accuracy: 0.9529\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 0.0943 - val_accuracy: 0.9765\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9765\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0177 - accuracy: 0.9987 - val_loss: 0.1084 - val_accuracy: 0.9765\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.1727 - val_accuracy: 0.9529\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0596 - val_accuracy: 0.9765\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0691 - val_accuracy: 0.9765\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0218 - accuracy: 0.9974 - val_loss: 0.1044 - val_accuracy: 0.9647\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9647\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.1032 - val_accuracy: 0.9765\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9765\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9765\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9765\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9765\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 0.1356 - val_accuracy: 0.9647\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9647\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9765\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9765\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9647\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.1688 - val_accuracy: 0.9765\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.1825 - val_accuracy: 0.9647\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0236 - accuracy: 0.9881 - val_loss: 0.2110 - val_accuracy: 0.9647\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0393 - accuracy: 0.9895 - val_loss: 0.2503 - val_accuracy: 0.9412\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0362 - accuracy: 0.9895 - val_loss: 0.2484 - val_accuracy: 0.9412\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.1612 - val_accuracy: 0.9412\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.1322 - val_accuracy: 0.9647\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.1577 - val_accuracy: 0.9529\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1373 - val_accuracy: 0.9529\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9765\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 7.0231e-04 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9765\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 3.8661e-04 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9765\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 6.8086e-04 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9765\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 7.3980e-04 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9765\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 5.1213e-04 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9765\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 3.0611e-04 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9765\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 0.1277 - val_accuracy: 0.9765\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 10s 612ms/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.1399 - val_accuracy: 0.9765\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.1534 - val_accuracy: 0.9647\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.2192 - val_accuracy: 0.9529\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 8.6979e-04 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9647\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9647\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.1920 - val_accuracy: 0.9529\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0238 - accuracy: 0.9895 - val_loss: 0.1546 - val_accuracy: 0.9529\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 0.1473 - val_accuracy: 0.9529\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 6.3668e-04 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9647\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 5.6370e-04 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9647\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 4.8948e-04 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9647\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 3.7412e-04 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9647\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9765\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 9.4420e-04 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9647\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9765\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 5.8217e-04 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9765\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 0.1375 - val_accuracy: 0.9765\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0578 - accuracy: 0.9842 - val_loss: 0.2846 - val_accuracy: 0.9294\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0642 - accuracy: 0.9816 - val_loss: 0.1433 - val_accuracy: 0.9647\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.1404 - val_accuracy: 0.9647\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.0884 - val_accuracy: 0.9765\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.1031 - val_accuracy: 0.9647\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.1361 - val_accuracy: 0.9647\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0985 - val_accuracy: 0.9765\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9765\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9765\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 0.1491 - val_accuracy: 0.9765\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 4.7664e-04 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9765\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 3.8681e-04 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9765\n",
            "Epoch 201/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 2.9739e-04 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9765\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 2.9805e-04 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9765\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 7.9673e-04 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9765\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 5.4979e-04 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9765\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 2.4134e-04 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9765\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 0.1391 - val_accuracy: 0.9765\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.8175e-04 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9765\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 4.2993e-04 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9765\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 8.4884e-04 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9765\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 1.8783e-04 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9765\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0166 - accuracy: 0.9974 - val_loss: 0.1026 - val_accuracy: 0.9765\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0556 - accuracy: 0.9842 - val_loss: 0.1152 - val_accuracy: 0.9529\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.2190 - val_accuracy: 0.9412\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9647\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1603 - val_accuracy: 0.9647\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.2231 - val_accuracy: 0.9412\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1467 - val_accuracy: 0.9647\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9647\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 5.2461e-04 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9529\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.1935 - val_accuracy: 0.9529\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.1126 - val_accuracy: 0.9765\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 5.3975e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9765\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 4.9993e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9765\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 5.6689e-04 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9765\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 3.8685e-04 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9765\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9765\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 11s 664ms/step - loss: 2.3890e-04 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9882\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0131 - accuracy: 0.9987 - val_loss: 0.0980 - val_accuracy: 0.9647\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.0910 - val_accuracy: 0.9765\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1261 - val_accuracy: 0.9647\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.1307 - val_accuracy: 0.9647\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9765\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 7.0115e-04 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9882\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 6.7730e-04 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9765\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1383 - val_accuracy: 0.9647\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0711 - accuracy: 0.9816 - val_loss: 0.2487 - val_accuracy: 0.9176\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.1620 - val_accuracy: 0.9529\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 8.0691e-04 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9529\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9529\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 0.1399 - val_accuracy: 0.9529\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 0.1388 - val_accuracy: 0.9765\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9647\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9647\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 8.8269e-04 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9647\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 4.2264e-04 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9647\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 10s 611ms/step - loss: 3.7637e-04 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9647\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 2.2363e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9647\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 8.7112e-04 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9765\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 10s 593ms/step - loss: 1.8777e-04 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9765\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 2.9075e-04 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9765\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 6.3516e-04 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9765\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 2.9993e-04 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9647\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 7.6938e-04 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9647\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 3.1600e-04 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9765\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.5668e-04 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9647\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 2.7773e-04 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9647\n",
            "Epoch 257/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.1458 - val_accuracy: 0.9765\n",
            "Epoch 258/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 0.1426 - val_accuracy: 0.9765\n",
            "Epoch 259/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 0.1532 - val_accuracy: 0.9765\n",
            "Epoch 260/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 8.4663e-04 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9647\n",
            "Epoch 261/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 4.4453e-04 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9647\n",
            "Epoch 262/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 3.8443e-04 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9647\n",
            "Epoch 263/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9647\n",
            "Epoch 264/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 0.1575 - val_accuracy: 0.9647\n",
            "Epoch 265/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.1226 - val_accuracy: 0.9765\n",
            "Epoch 266/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1337 - val_accuracy: 0.9765\n",
            "Epoch 267/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1264 - val_accuracy: 0.9647\n",
            "Epoch 268/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.1399 - val_accuracy: 0.9647\n",
            "Epoch 269/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0366 - accuracy: 0.9816 - val_loss: 0.1687 - val_accuracy: 0.9529\n",
            "Epoch 270/1000\n",
            "16/16 [==============================] - 10s 614ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.1363 - val_accuracy: 0.9765\n",
            "Epoch 271/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.1631 - val_accuracy: 0.9647\n",
            "Epoch 272/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.1706 - val_accuracy: 0.9529\n",
            "Epoch 273/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.1718 - val_accuracy: 0.9647\n",
            "Epoch 274/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.1445 - val_accuracy: 0.9765\n",
            "Epoch 275/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 5.9870e-04 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9765\n",
            "Epoch 276/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 7.3174e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9882\n",
            "Epoch 277/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9882\n",
            "Epoch 278/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1137 - val_accuracy: 0.9765\n",
            "Epoch 279/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.1049 - val_accuracy: 0.9882\n",
            "Epoch 280/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0941 - val_accuracy: 0.9765\n",
            "Epoch 281/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0195 - accuracy: 0.9908 - val_loss: 0.1191 - val_accuracy: 0.9765\n",
            "Epoch 282/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0249 - accuracy: 0.9947 - val_loss: 0.1541 - val_accuracy: 0.9647\n",
            "Epoch 283/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0718 - accuracy: 0.9802 - val_loss: 0.1388 - val_accuracy: 0.9647\n",
            "Epoch 284/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9765\n",
            "Epoch 285/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9647\n",
            "Epoch 286/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1586 - val_accuracy: 0.9647\n",
            "Epoch 287/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1559 - val_accuracy: 0.9647\n",
            "Epoch 288/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1466 - val_accuracy: 0.9647\n",
            "Epoch 289/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9647\n",
            "Epoch 290/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 7.8471e-04 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9647\n",
            "Epoch 291/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 3.2996e-04 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9647\n",
            "Epoch 292/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 4.2209e-04 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9647\n",
            "Epoch 293/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 3.1817e-04 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9647\n",
            "Epoch 294/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 2.8636e-04 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9647\n",
            "Epoch 295/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 3.2457e-04 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9647\n",
            "Epoch 296/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1389 - val_accuracy: 0.9647\n",
            "Epoch 297/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0230 - accuracy: 0.9960 - val_loss: 0.1530 - val_accuracy: 0.9529\n",
            "Epoch 298/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.1522 - val_accuracy: 0.9647\n",
            "Epoch 299/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9647\n",
            "Epoch 300/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.1425 - val_accuracy: 0.9765\n",
            "Epoch 301/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9647\n",
            "Epoch 302/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 0.1345 - val_accuracy: 0.9647\n",
            "Epoch 303/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 5.1196e-04 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9765\n",
            "Epoch 304/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 0.1333 - val_accuracy: 0.9765\n",
            "Epoch 305/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 7.3815e-04 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9765\n",
            "Epoch 306/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 8.1218e-04 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9765\n",
            "Epoch 307/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0014 - accuracy: 0.9987 - val_loss: 0.1633 - val_accuracy: 0.9647\n",
            "Epoch 308/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.8949e-04 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9647\n",
            "Epoch 309/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 3.4967e-04 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9647\n",
            "Epoch 310/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9647\n",
            "Epoch 311/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1541 - val_accuracy: 0.9647\n",
            "Epoch 312/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 0.1965 - val_accuracy: 0.9765\n",
            "Epoch 313/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 4.2607e-04 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9765\n",
            "Epoch 314/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.1926 - val_accuracy: 0.9765\n",
            "Epoch 315/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 2.0555e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9647\n",
            "Epoch 316/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.7474e-04 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9765\n",
            "Epoch 317/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.6787e-04 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9765\n",
            "Epoch 318/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.0981e-04 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9765\n",
            "Epoch 319/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 2.0597e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9765\n",
            "Epoch 320/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.0003e-04 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9765\n",
            "Epoch 321/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.1682 - val_accuracy: 0.9765\n",
            "Epoch 322/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 0.1385 - val_accuracy: 0.9529\n",
            "Epoch 323/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 9.6358e-04 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9647\n",
            "Epoch 324/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9529\n",
            "Epoch 325/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 8.7765e-04 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9529\n",
            "Epoch 326/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 3.8624e-04 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9529\n",
            "Epoch 327/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 3.1808e-04 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9529\n",
            "Epoch 328/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 6.0551e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9529\n",
            "Epoch 329/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 8.0865e-04 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9529\n",
            "Epoch 330/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9529\n",
            "Epoch 331/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9647\n",
            "Epoch 332/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.7929e-04 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9647\n",
            "Epoch 333/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.5862e-04 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9647\n",
            "Epoch 334/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 6.7217e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9647\n",
            "Epoch 335/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 2.9635e-04 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9647\n",
            "Epoch 336/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 2.5933e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9647\n",
            "Epoch 337/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 2.4265e-04 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9647\n",
            "Epoch 338/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 4.7714e-04 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9647\n",
            "Epoch 339/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 9.1362e-05 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9647\n",
            "Epoch 340/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 6.6641e-04 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9647\n",
            "Epoch 341/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 2.6725e-04 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9647\n",
            "Epoch 342/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0014 - accuracy: 0.9987 - val_loss: 0.1948 - val_accuracy: 0.9765\n",
            "Epoch 343/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1842 - val_accuracy: 0.9647\n",
            "Epoch 344/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0253 - accuracy: 0.9895 - val_loss: 0.1865 - val_accuracy: 0.9647\n",
            "Epoch 345/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 0.1790 - val_accuracy: 0.9765\n",
            "Epoch 346/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9765\n",
            "Epoch 347/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 8.4613e-05 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9647\n",
            "Epoch 348/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.1014e-04 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9647\n",
            "Epoch 349/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.7505e-04 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9647\n",
            "Epoch 350/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.0019e-04 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9765\n",
            "Epoch 351/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.1557e-04 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9765\n",
            "Epoch 352/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.1856 - val_accuracy: 0.9765\n",
            "Epoch 353/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0239 - accuracy: 0.9908 - val_loss: 0.2054 - val_accuracy: 0.9647\n",
            "Epoch 354/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 2.5745e-04 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9765\n",
            "Epoch 355/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 4.7696e-04 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9647\n",
            "Epoch 356/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 2.5900e-04 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9765\n",
            "Epoch 357/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 4.1952e-04 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9765\n",
            "Epoch 358/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 1.5950e-04 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9765\n",
            "Epoch 359/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 7.3114e-05 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9765\n",
            "Epoch 360/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.3860e-04 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9765\n",
            "Epoch 361/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 5.7673e-05 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9765\n",
            "Epoch 362/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 8.1361e-05 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9765\n",
            "Epoch 363/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.2609e-04 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9765\n",
            "Epoch 364/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0014 - accuracy: 0.9987 - val_loss: 0.1942 - val_accuracy: 0.9765\n",
            "Epoch 365/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.2080 - val_accuracy: 0.9647\n",
            "Epoch 366/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.2185 - val_accuracy: 0.9647\n",
            "Epoch 367/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9647\n",
            "Epoch 368/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 5.6385e-04 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9647\n",
            "Epoch 369/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 3.8562e-04 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9647\n",
            "Epoch 370/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 7.1042e-04 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9647\n",
            "Epoch 371/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 2.9343e-04 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9647\n",
            "Epoch 372/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9647\n",
            "Epoch 373/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 4.4336e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9647\n",
            "Epoch 374/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 0.2239 - val_accuracy: 0.9765\n",
            "Epoch 375/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9765\n",
            "Epoch 376/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9529\n",
            "Epoch 377/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 0.2186 - val_accuracy: 0.9765\n",
            "Epoch 378/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.2140 - val_accuracy: 0.9765\n",
            "Epoch 379/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0083 - accuracy: 0.9960 - val_loss: 0.1925 - val_accuracy: 0.9765\n",
            "Epoch 380/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 0.1799 - val_accuracy: 0.9765\n",
            "Epoch 381/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 4.6434e-04 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9765\n",
            "Epoch 382/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.7151e-04 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9765\n",
            "Epoch 383/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 2.6065e-04 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9765\n",
            "Epoch 384/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 5.5760e-04 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9765\n",
            "Epoch 385/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.2628e-04 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9765\n",
            "Epoch 386/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.0341e-04 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9765\n",
            "Epoch 387/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 1.1767e-04 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9765\n",
            "Epoch 388/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.0579e-04 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9765\n",
            "Epoch 389/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.1238e-04 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9765\n",
            "Epoch 390/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.7113e-04 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9765\n",
            "Epoch 391/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 2.0248e-04 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9765\n",
            "Epoch 392/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.0799e-04 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9765\n",
            "Epoch 393/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 2.0622e-04 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9765\n",
            "Epoch 394/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.0251e-04 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9765\n",
            "Epoch 395/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.0118e-04 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9765\n",
            "Epoch 396/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.1311e-04 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9765\n",
            "Epoch 397/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 9.1755e-05 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9765\n",
            "Epoch 398/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 8.1248e-05 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9765\n",
            "Epoch 399/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 5.2967e-05 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9765\n",
            "Epoch 400/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.3125e-04 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9765\n",
            "Epoch 401/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 6.4484e-04 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9765\n",
            "Epoch 402/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 6.4825e-04 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9765\n",
            "Epoch 403/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 4.6375e-04 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9765\n",
            "Epoch 404/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.7970e-04 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9765\n",
            "Epoch 405/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 5.0076e-05 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9765\n",
            "Epoch 406/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 7.6179e-05 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9765\n",
            "Epoch 407/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 4.7252e-05 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9765\n",
            "Epoch 408/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.0011 - accuracy: 0.9987 - val_loss: 0.1959 - val_accuracy: 0.9765\n",
            "Epoch 409/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.2682e-04 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9765\n",
            "Epoch 410/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 5.3172e-05 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9765\n",
            "Epoch 411/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 6.3903e-05 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9765\n",
            "Epoch 412/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 1.1008e-04 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9765\n",
            "Epoch 413/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 5.5590e-04 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9765\n",
            "Epoch 414/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.0993e-04 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9765\n",
            "Epoch 415/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 2.7307e-04 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9765\n",
            "Epoch 416/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.4119e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9765\n",
            "Epoch 417/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.1605e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9765\n",
            "Epoch 418/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 1.2025e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9765\n",
            "Epoch 419/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 5.2707e-04 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9765\n",
            "Epoch 420/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 2.3163e-04 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9765\n",
            "Epoch 421/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 6.2618e-05 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9765\n",
            "Epoch 422/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 7.5437e-05 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9765\n",
            "Epoch 423/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 8.0581e-05 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9765\n",
            "Epoch 424/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 3.0516e-05 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9765\n",
            "Epoch 425/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 8.1738e-05 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9765\n",
            "Epoch 426/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 2.6318e-05 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9765\n",
            "Epoch 427/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 8.8725e-05 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 227.\n",
            "16/16 [==============================] - 10s 637ms/step - loss: 8.8725e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9765\n",
            "Epoch 427: early stopping\n",
            "7/7 [==============================] - 3s 191ms/step\n",
            "resnet done\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 50176)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4096)              205524992 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1000)              4097000   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 1001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 233,441,809\n",
            "Trainable params: 233,358,161\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "16/16 [==============================] - 34s 1s/step - loss: 0.5092 - accuracy: 0.7391 - val_loss: 0.6966 - val_accuracy: 0.5176\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.2937 - accuracy: 0.8827 - val_loss: 0.7236 - val_accuracy: 0.5176\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 9s 584ms/step - loss: 0.2426 - accuracy: 0.9038 - val_loss: 0.7598 - val_accuracy: 0.5176\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 9s 587ms/step - loss: 0.1998 - accuracy: 0.9289 - val_loss: 0.8816 - val_accuracy: 0.5176\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 9s 588ms/step - loss: 0.1300 - accuracy: 0.9565 - val_loss: 0.8905 - val_accuracy: 0.5176\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 9s 591ms/step - loss: 0.0889 - accuracy: 0.9671 - val_loss: 1.0320 - val_accuracy: 0.5176\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0721 - accuracy: 0.9776 - val_loss: 1.0542 - val_accuracy: 0.5176\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 0.0618 - accuracy: 0.9802 - val_loss: 1.5009 - val_accuracy: 0.5176\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0594 - accuracy: 0.9789 - val_loss: 1.4044 - val_accuracy: 0.5176\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0398 - accuracy: 0.9934 - val_loss: 1.7577 - val_accuracy: 0.5176\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.1370 - accuracy: 0.9486 - val_loss: 1.9941 - val_accuracy: 0.5176\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 9s 590ms/step - loss: 0.1083 - accuracy: 0.9526 - val_loss: 1.7587 - val_accuracy: 0.5176\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0597 - accuracy: 0.9789 - val_loss: 1.9812 - val_accuracy: 0.5176\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0797 - accuracy: 0.9776 - val_loss: 1.9880 - val_accuracy: 0.5176\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0895 - accuracy: 0.9671 - val_loss: 1.1289 - val_accuracy: 0.5176\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 10s 642ms/step - loss: 0.0912 - accuracy: 0.9671 - val_loss: 0.7481 - val_accuracy: 0.6235\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 0.0486 - accuracy: 0.9855 - val_loss: 0.7886 - val_accuracy: 0.6235\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 1.1456 - val_accuracy: 0.5529\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 10s 634ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.6668 - val_accuracy: 0.6824\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0627 - accuracy: 0.9750 - val_loss: 1.7285 - val_accuracy: 0.5412\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 10s 641ms/step - loss: 0.0628 - accuracy: 0.9816 - val_loss: 0.9005 - val_accuracy: 0.7176\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 10s 635ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.5767 - val_accuracy: 0.7294\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 10s 639ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.4509 - val_accuracy: 0.8000\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 10s 633ms/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 0.4366 - val_accuracy: 0.8588\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 10s 638ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.8824\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 10s 639ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.3752 - val_accuracy: 0.9059\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 0.7710 - val_accuracy: 0.7412\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0514 - accuracy: 0.9829 - val_loss: 0.8044 - val_accuracy: 0.8000\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.6593 - val_accuracy: 0.7882\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0108 - accuracy: 0.9987 - val_loss: 0.4344 - val_accuracy: 0.8353\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.4219 - val_accuracy: 0.8235\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0312 - accuracy: 0.9868 - val_loss: 0.7813 - val_accuracy: 0.7882\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0255 - accuracy: 0.9895 - val_loss: 1.1616 - val_accuracy: 0.5882\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 1.8684 - val_accuracy: 0.5412\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.7882\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 10s 640ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0923 - val_accuracy: 0.9529\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9412\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.1562 - val_accuracy: 0.9412\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0426 - accuracy: 0.9842 - val_loss: 0.6680 - val_accuracy: 0.8824\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0301 - accuracy: 0.9868 - val_loss: 1.1414 - val_accuracy: 0.6824\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.3381 - val_accuracy: 0.9294\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 10s 600ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.1748 - val_accuracy: 0.9176\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.1233 - val_accuracy: 0.9294\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0443 - accuracy: 0.9816 - val_loss: 4.7030 - val_accuracy: 0.5529\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0402 - accuracy: 0.9855 - val_loss: 7.4630 - val_accuracy: 0.5176\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0369 - accuracy: 0.9868 - val_loss: 8.8973 - val_accuracy: 0.5059\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.1461 - accuracy: 0.9499 - val_loss: 15.2156 - val_accuracy: 0.4824\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0431 - accuracy: 0.9908 - val_loss: 23.5017 - val_accuracy: 0.4824\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0202 - accuracy: 0.9895 - val_loss: 14.0864 - val_accuracy: 0.4824\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 0.0118 - accuracy: 0.9987 - val_loss: 7.5034 - val_accuracy: 0.4824\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 5.9835 - val_accuracy: 0.4941\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 5.8208 - val_accuracy: 0.5294\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 7.5309 - val_accuracy: 0.5059\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 5.9650 - val_accuracy: 0.5176\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 2.2352 - val_accuracy: 0.6235\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.6623 - val_accuracy: 0.8353\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.8941\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9529\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 10s 634ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9765\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 10s 639ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9882\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 4.2469 - val_accuracy: 0.6353\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9464 - val_accuracy: 0.6941\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.7000 - val_accuracy: 0.7294\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 8.4816 - val_accuracy: 0.5176\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0129 - accuracy: 0.9921 - val_loss: 8.7509 - val_accuracy: 0.5059\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 10s 600ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 6.1249 - val_accuracy: 0.5412\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0696 - val_accuracy: 0.6471\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5967 - val_accuracy: 0.7176\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.8941\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 9.9255e-04 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9412\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9412\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.2633 - val_accuracy: 0.9294\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9412\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0210 - accuracy: 0.9947 - val_loss: 0.0908 - val_accuracy: 0.9765\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.2693 - accuracy: 0.9289 - val_loss: 16.5105 - val_accuracy: 0.4824\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0547 - accuracy: 0.9816 - val_loss: 20.3412 - val_accuracy: 0.4824\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0200 - accuracy: 0.9908 - val_loss: 12.2720 - val_accuracy: 0.4824\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 9s 594ms/step - loss: 0.0190 - accuracy: 0.9921 - val_loss: 5.9925 - val_accuracy: 0.5412\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 3.9926 - val_accuracy: 0.5529\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 2.1035 - val_accuracy: 0.5765\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 4.9852 - val_accuracy: 0.4941\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 4.7805 - val_accuracy: 0.5294\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0152 - val_accuracy: 0.5647\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0115 - accuracy: 0.9947 - val_loss: 1.2583 - val_accuracy: 0.7412\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 4.7056 - val_accuracy: 0.5412\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.8145 - val_accuracy: 0.6000\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 10s 593ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 2.0665 - val_accuracy: 0.6941\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 0.7293 - val_accuracy: 0.7765\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.7941 - val_accuracy: 0.7882\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0147 - accuracy: 0.9934 - val_loss: 0.8000 - val_accuracy: 0.8000\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 1.6542 - val_accuracy: 0.7176\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 1.6052 - val_accuracy: 0.7294\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 1.1868 - val_accuracy: 0.8000\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 0.0043 - accuracy: 0.9974 - val_loss: 1.5831 - val_accuracy: 0.7647\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0191 - val_accuracy: 0.8235\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.8471\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9176\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 7.0831e-04 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9412\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9412\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9412\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.1709 - val_accuracy: 0.9412\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 0.3713 - val_accuracy: 0.8706\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.0636 - val_accuracy: 0.9765\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 1.2436 - val_accuracy: 0.7647\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.3939 - val_accuracy: 0.8471\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: 0.4440 - val_accuracy: 0.8471\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.7294\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.6953 - val_accuracy: 0.7882\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 6.7540e-04 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8588\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 8.3985e-04 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.8706\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.8941\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 7.7115e-04 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9176\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 9.1682e-04 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9647\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1286 - val_accuracy: 0.9529\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0928 - val_accuracy: 0.9529\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0144 - accuracy: 0.9987 - val_loss: 0.7668 - val_accuracy: 0.8000\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0117 - accuracy: 0.9987 - val_loss: 0.1827 - val_accuracy: 0.9529\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1592 - val_accuracy: 0.9176\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.2864 - val_accuracy: 0.9059\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 8.9975e-04 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9412\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 6.3404e-04 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9412\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 5.7798e-04 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9529\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 7.4960e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9529\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.1252 - val_accuracy: 0.9412\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 7.7479e-04 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9529\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 6.1467e-04 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9529\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 4.4224e-04 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9529\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 3.5807e-04 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9647\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 3.1744e-04 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9647\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 2.5370e-04 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9765\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 2.6401e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9765\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 4.3520e-04 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9765\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 5.2923e-04 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9647\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9647\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 4.4716e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9765\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 2.0719e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9765\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 4.6250e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9765\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.0826 - val_accuracy: 0.9765\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 1.1243 - val_accuracy: 0.8235\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.6163 - val_accuracy: 0.8471\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.9073 - val_accuracy: 0.8118\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1544 - val_accuracy: 0.8000\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.8824\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9294\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 4.3612e-04 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9294\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 10s 599ms/step - loss: 4.2025e-04 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9529\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 6.1262e-04 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9529\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 3.8684e-04 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9529\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 1.6449e-04 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9529\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.1316 - val_accuracy: 0.9412\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 4.2797 - val_accuracy: 0.6353\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 5.4710e-04 - accuracy: 1.0000 - val_loss: 8.7387 - val_accuracy: 0.5412\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 9.5004e-04 - accuracy: 1.0000 - val_loss: 6.1772 - val_accuracy: 0.5882\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 3.5824e-04 - accuracy: 1.0000 - val_loss: 3.8064 - val_accuracy: 0.6471\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 2.7116 - val_accuracy: 0.6824\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0213 - val_accuracy: 0.7294\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0030 - accuracy: 0.9974 - val_loss: 0.9429 - val_accuracy: 0.8588\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0045 - accuracy: 0.9974 - val_loss: 0.3419 - val_accuracy: 0.8824\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0262 - accuracy: 0.9947 - val_loss: 0.3184 - val_accuracy: 0.8706\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.8941\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 8.1223e-04 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.8941\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 10s 600ms/step - loss: 4.7681e-04 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9294\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9529\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.1177 - val_accuracy: 0.9765\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 9s 592ms/step - loss: 5.9020e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9765\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9765\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 3.7376e-04 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9765\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 5.0842e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9765\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 4.6683e-04 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9765\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 10s 599ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9765\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9882\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.8295 - val_accuracy: 0.8353\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9148 - val_accuracy: 0.8235\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 3.4255e-04 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.8824\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 9.3605e-04 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9176\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 13.3303 - val_accuracy: 0.5294\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 8.6594 - val_accuracy: 0.5529\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 3.1631 - val_accuracy: 0.6941\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 10s 593ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 1.0915 - val_accuracy: 0.7882\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0071 - accuracy: 0.9947 - val_loss: 1.7674 - val_accuracy: 0.7882\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2208 - val_accuracy: 0.8235\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.8941\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9294\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 6.2111e-04 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9647\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 6.9577e-04 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9529\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 5.8890e-04 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9412\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 4.7397e-04 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9412\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 9.1567e-04 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9647\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 8.0631e-04 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9765\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 9.0993e-04 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9765\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0752 - val_accuracy: 0.9647\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.1463 - val_accuracy: 0.9647\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 3.7209e-04 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9412\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 10s 600ms/step - loss: 3.6893e-04 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9529\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 2.3390e-04 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9529\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 9.4779e-04 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9529\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 2.9683e-04 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9647\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 2.0224e-04 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9647\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 4.3236e-04 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9647\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 6.7154e-04 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9294\n",
            "Epoch 201/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 0.2307 - val_accuracy: 0.9294\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.2616 - val_accuracy: 0.9412\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8854 - val_accuracy: 0.7882\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5369 - val_accuracy: 0.7294\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 1.6818 - val_accuracy: 0.6824\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 7.3791e-04 - accuracy: 1.0000 - val_loss: 1.0374 - val_accuracy: 0.8118\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 10s 599ms/step - loss: 3.6460e-04 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.8941\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8941\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9294\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.7477 - val_accuracy: 0.7647\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 1.1987 - val_accuracy: 0.7176\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 3.7476e-04 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.7294\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 4.3951e-04 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.8353\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 1.6572e-04 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9059\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 2.0328e-04 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9647\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 9.3270e-04 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9647\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 10s 597ms/step - loss: 4.8383e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9647\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 4.1766e-04 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9647\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 2.3620e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9294\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 10s 600ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.3563 - val_accuracy: 0.9294\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 6.3171e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.8941\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 3.4225e-04 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.8941\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 9.6363e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9294\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8383 - val_accuracy: 0.8118\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.8941\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9529\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 2.5755e-04 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9529\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 1.1925e-04 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9529\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 7.1473e-05 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9529\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 1.8903e-04 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9529\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.5495e-04 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9412\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 1.9817e-04 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9529\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 2.0744e-04 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9647\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 9.7548e-04 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9529\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 8.4249e-05 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9647\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 10s 598ms/step - loss: 7.3519e-05 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9647\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 5.5798e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9529\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 1.3377e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9529\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 10s 599ms/step - loss: 4.9798e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9529\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 10s 617ms/step - loss: 2.2671e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9529\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 9.3646e-05 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9529\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 6.8164e-05 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9529\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 1.1287e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9529\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 1.7438e-04 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9529\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 5.4211e-05 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9529\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 8.3955e-05 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9529\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 5.0576e-05 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9529\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 1.0174e-04 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9529\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 10s 601ms/step - loss: 1.0540e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9529\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 6.1563e-05 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9529\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 8.2110e-05 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9529\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 10s 594ms/step - loss: 3.5097e-04 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9529\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.4420 - val_accuracy: 0.8941\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 10s 595ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.0712 - val_accuracy: 0.6118\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.9536 - val_accuracy: 0.7412\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 4.0798e-04 - accuracy: 1.0000 - val_loss: 0.6417 - val_accuracy: 0.8824\n",
            "Epoch 257/1000\n",
            "16/16 [==============================] - 10s 600ms/step - loss: 2.1533e-04 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9412\n",
            "Epoch 258/1000\n",
            "16/16 [==============================] - 9s 593ms/step - loss: 0.0014 - accuracy: 0.9987 - val_loss: 0.1874 - val_accuracy: 0.9647\n",
            "Epoch 259/1000\n",
            "16/16 [==============================] - 10s 596ms/step - loss: 1.6521e-04 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9529\n",
            "Epoch 260/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9015e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 60.\n",
            "16/16 [==============================] - 10s 627ms/step - loss: 1.9015e-04 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9529\n",
            "Epoch 260: early stopping\n",
            "7/7 [==============================] - 6s 293ms/step\n",
            "densenet done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculation of Accuracy, Sensitivity, Specificity, Precision, Recall and AUC Value"
      ],
      "metadata": {
        "id": "mgPcX-aUEXLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(testPreds1)\n",
        "tp1 = []\n",
        "for i in testPreds1:\n",
        "  if i < 0.5:\n",
        "    tp1.append(0)\n",
        "  else:\n",
        "    tp1.append(1)\n",
        "# print(testPreds)\n",
        "tp2 = []\n",
        "for i in testPreds2:\n",
        "  if i < 0.5:\n",
        "    tp2.append(0)\n",
        "  else:\n",
        "    tp2.append(1)\n",
        "\n",
        "# print(testPreds1)\n",
        "tp3 = []\n",
        "for i in testPreds3:\n",
        "  if i < 0.5:\n",
        "    tp3.append(0)\n",
        "  else:\n",
        "    tp3.append(1)\n",
        "\n",
        "cm = confusion_matrix(yTest, tp1)\n",
        "sensitivity1 = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity1 = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "precision1 = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
        "recall1 = cm[1, 1] / (cm[0, 1] + cm[1, 1])\n",
        "accuracy1 = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0])\n",
        "print(\"For inceptionv3\")\n",
        "print(\"\\n Accuracy: \",accuracy1)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity1)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity1)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision1)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall1)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, tp1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cm = confusion_matrix(yTest, tp2)\n",
        "sensitivity2 = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity2 = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "precision2 = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
        "recall2 = cm[1, 1] / (cm[0, 1] + cm[1, 1])\n",
        "accuracy2 = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0])\n",
        "print(\"\\n\\nFor Resnet\")\n",
        "print(\"\\n Accuracy: \",accuracy2)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity2)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity2)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision2)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall2)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, tp2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cm = confusion_matrix(yTest, tp3)\n",
        "sensitivity3 = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity3 = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "precision3 = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
        "recall3 = cm[1, 1] / (cm[0, 1] + cm[1, 1])\n",
        "accuracy3 = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0])\n",
        "print(\"\\n\\nFor DenseNet\")\n",
        "print(\"\\n Accuracy: \",accuracy3)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity3)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity3)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision3)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall3)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, tp3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_VQtctCXj9_",
        "outputId": "12514430-d47b-44d6-d171-30950c0cfcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For inceptionv3\n",
            "\n",
            " Accuracy:  0.9620853080568721\n",
            "\n",
            "\n",
            " Sensitivity:  0.925531914893617\n",
            "\n",
            "\n",
            " Specificity:  0.9914529914529915\n",
            "\n",
            "\n",
            " Precision:  0.9886363636363636\n",
            "\n",
            "\n",
            " Recall:  0.943089430894309\n",
            "\n",
            "AUC Value:  0.9584924531733042\n",
            "\n",
            "\n",
            "For Resnet\n",
            "\n",
            " Accuracy:  0.957345971563981\n",
            "\n",
            "\n",
            " Sensitivity:  0.9680851063829787\n",
            "\n",
            "\n",
            " Specificity:  0.9487179487179487\n",
            "\n",
            "\n",
            " Precision:  0.9381443298969072\n",
            "\n",
            "\n",
            " Recall:  0.9736842105263158\n",
            "\n",
            "AUC Value:  0.9584015275504637\n",
            "\n",
            "\n",
            "For DenseNet\n",
            "\n",
            " Accuracy:  0.933649289099526\n",
            "\n",
            "\n",
            " Sensitivity:  0.9361702127659575\n",
            "\n",
            "\n",
            " Specificity:  0.9316239316239316\n",
            "\n",
            "\n",
            " Precision:  0.9166666666666666\n",
            "\n",
            "\n",
            " Recall:  0.9478260869565217\n",
            "\n",
            "AUC Value:  0.9338970721949446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix for InceptionV3"
      ],
      "metadata": {
        "id": "vwATA5MVDhrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "class_labels = [\"Abnormal(Ulcer)\",\"Normal(Healthy skin)\"]\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "plt.figure(figsize=(16,9))\n",
        "y_pred_labels = [ np.argmax(label) for label in testPreds1]\n",
        "# cm = confusion_matrix(yTest, y_pred_labels)\n",
        "cm = confusion_matrix(yTest, tp1)\n",
        "sns.heatmap(cm, annot = True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "iZ1pfFsdcf00",
        "outputId": "75550b3e-88b2-433c-8ae7-3229aa10e9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efe12232e90>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix for ResNet"
      ],
      "metadata": {
        "id": "mp8R6uvwDsBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "y_pred_labels = [ np.argmax(label) for label in testPreds2]\n",
        "cm = confusion_matrix(yTest, tp2)\n",
        "sns.heatmap(cm, annot = True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "HVbKf6bigfdx",
        "outputId": "a60eb8c8-2eca-49b2-dfb1-b2c534430957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efe1205c690>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix for DenseNet"
      ],
      "metadata": {
        "id": "oK8o-UnKs1yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "y_pred_labels = [ np.argmax(label) for label in testPreds3]\n",
        "cm = confusion_matrix(yTest, tp3)\n",
        "sns.heatmap(cm, annot = True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "6o0h9PVOgl1-",
        "outputId": "7f8afd7d-f64d-4f37-8bd2-e4400272b712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efe1204e210>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import warnings\n",
        "# warnings.filterwarnings('always')\n",
        "# from sklearn.metrics import classification_report\n",
        "# y_pred_labels = [np.argmax(tp1) for tp1 in testPreds1]\n",
        "# cr= classification_report(yTest, y_pred_labels, target_names=class_labels)\n",
        "# print(cr)\n",
        "# print(yTest)\n",
        "# print(y_pred_labels)\n",
        "# print(class_labels)\n",
        "# print(testPreds1)\n",
        "# print(label)"
      ],
      "metadata": {
        "id": "FAFsm6I0gqBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate F1 Score"
      ],
      "metadata": {
        "id": "SFPh8q6ADzMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score1 = 2 * (precision1 * recall1) / (precision1 + recall1)\n",
        "# f1 = f1_score(yTest, testPreds1)\n",
        "print(f1_score1)\n",
        "\n",
        "f1_score2 = 2 * (precision2 * recall2) / (precision2 + recall2)\n",
        "# f1 = f1_score(yTest, testPreds1)\n",
        "print(f1_score2)\n",
        "\n",
        "f1_score3 = 2 * (precision3 * recall3) / (precision3 + recall3)\n",
        "# f1 = f1_score(yTest, testPreds1)\n",
        "print(f1_score3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B6S4Yz413CD",
        "outputId": "957a9046-e661-4a0a-9f39-5b3484b3cee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9653259361997226\n",
            "0.9555839364268484\n",
            "0.9319860085503303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification Report"
      ],
      "metadata": {
        "id": "sF1Hf30kD38l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "table = [['Model Name','Accuracy','Sensitivity','Specificity', 'Precision', 'Recall','F1 Score', 'AUC Value'],\n",
        "\n",
        "         ['inceptionv3', accuracy1, sensitivity1, specificity1, precision1, recall1,f1_score1, roc_auc_score(yTest, tp1)],\n",
        "         ['Resnet', accuracy2, sensitivity2, specificity2, precision2, recall2,f1_score2, roc_auc_score(yTest, tp2)],\n",
        "         ['DenseNet',accuracy3, sensitivity3, specificity3, precision3, recall3,f1_score3, roc_auc_score(yTest, tp3)]]\n",
        "\n",
        "print(tabulate(table, headers='firstrow', tablefmt='grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xYKRg7HvHvE",
        "outputId": "e6182a58-1075-406a-fc01-3e57d936df8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+---------------+---------------+-------------+----------+------------+-------------+\n",
            "| Model Name   |   Accuracy |   Sensitivity |   Specificity |   Precision |   Recall |   F1 Score |   AUC Value |\n",
            "+==============+============+===============+===============+=============+==========+============+=============+\n",
            "| inceptionv3  |   0.962085 |      0.925532 |      0.991453 |    0.988636 | 0.943089 |   0.965326 |    0.958492 |\n",
            "+--------------+------------+---------------+---------------+-------------+----------+------------+-------------+\n",
            "| Resnet       |   0.957346 |      0.968085 |      0.948718 |    0.938144 | 0.973684 |   0.955584 |    0.958402 |\n",
            "+--------------+------------+---------------+---------------+-------------+----------+------------+-------------+\n",
            "| DenseNet     |   0.933649 |      0.93617  |      0.931624 |    0.916667 | 0.947826 |   0.931986 |    0.933897 |\n",
            "+--------------+------------+---------------+---------------+-------------+----------+------------+-------------+\n"
          ]
        }
      ]
    }
  ]
}